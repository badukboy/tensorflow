{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Vector. 1-Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[312]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [312]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Const_17:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'Shape_14:0' shape=(1,) dtype=int32>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([312])\n",
    "a, tf.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [1., 2., 3.]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Const_18:0' shape=(3,) dtype=float32>,\n",
       " <tf.Tensor 'Shape_15:0' shape=(1,) dtype=int32>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.constant([1., 2., 3.])\n",
    "b, tf.shape(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Matrix. 2-Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [  [1,2,3]\n",
    "     , [4,5,6]]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Const_10:0' shape=(2, 3) dtype=int32>,\n",
       " <tf.Tensor 'Shape_10:0' shape=(2,) dtype=int32>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.constant([  [1,2,3]\n",
    "                 , [4,5,6]])\n",
    "c, tf.shape(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. 3-Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1], [2], [3]], [[4], [5], [6]], [[7], [8], [9]]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = [  [[1],[2],[3]]\n",
    "     , [[4],[5],[6]]\n",
    "     , [[7],[8],[9]]]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Const_11:0' shape=(3, 3, 1) dtype=int32>,\n",
       " <tf.Tensor 'Shape_11:0' shape=(3,) dtype=int32>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = tf.constant([  [[1],[2],[3]]\n",
    "                 , [[4],[5],[6]]\n",
    "                 , [[7],[8],[9]]])\n",
    "d, tf.shape(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. 4-Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Const_12:0' shape=(1, 2, 3, 4) dtype=int32>,\n",
       " <tf.Tensor 'Shape_12:0' shape=(4,) dtype=int32>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = tf.constant(## axis = 0 \n",
    "                    [## axis = 1\n",
    "                     [## aixs = 2\n",
    "                       [## axis = 3\n",
    "                        [1,2,3,4]\n",
    "                       ,[5,6,7,8]\n",
    "                       ,[9,10,11,12]\n",
    "                       ],\n",
    "                        [\n",
    "                         [13,14,15,16]\n",
    "                        ,[17,18,19,20]\n",
    "                        ,[21,22,23,24]\n",
    "                       ]\n",
    "                      ]\n",
    "                ])\n",
    "e, tf.shape(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-5. tf.matmul\n",
    "\n",
    "matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Const_21:0' shape=(2, 2) dtype=int32>,\n",
       " <tf.Tensor 'Const_22:0' shape=(2, 1) dtype=int32>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = tf.constant([[1,2], [3,4]])\n",
    "m2 = tf.constant([[1], [2]])\n",
    "m1, m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul_5:0' shape=(2, 1) dtype=int32>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m12 = tf.matmul(m1, m2)\n",
    "m12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1]\n",
      " [2]]\n",
      "[[ 5]\n",
      " [11]]\n"
     ]
    }
   ],
   "source": [
    "## tensorflow 실행\n",
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run(m1))\n",
    "print(sess.run(m2))\n",
    "print(sess.run(m12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주의\n",
    "\n",
    "일반 행렬 곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [6 8]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(m1 * m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting. Tensor shape이 다르더라도 합의 연산이 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(m1 + m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------\n",
    "### 1-6. axis 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Const_24:0' shape=(2, 2) dtype=float32>,\n",
       " TensorShape([Dimension(2), Dimension(2)]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1.,2.], [3.,4.]])\n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.reduce_mean(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  3.]\n",
      "[ 1.5  3.5]\n",
      "[ 1.5  3.5]\n"
     ]
    }
   ],
   "source": [
    "## reduce_mean axis 연산\n",
    "\n",
    "print(sess.run(tf.reduce_mean(a, axis =  0)))\n",
    "print(sess.run(tf.reduce_mean(a, axis =  1)))\n",
    "print(sess.run(tf.reduce_mean(a, axis = -1))) ## -1 : 가장 안쪽에 있는 axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1]\n",
      "[2 2]\n",
      "[2 2]\n"
     ]
    }
   ],
   "source": [
    "## argmax axis 연산\n",
    "b = tf.constant([[1.,2.,5.], [3.,0.,7.]])\n",
    "\n",
    "print(sess.run(tf.argmax(b, axis =  0)))\n",
    "print(sess.run(tf.argmax(b, axis =  1)))\n",
    "print(sess.run(tf.argmax(b, axis = -1))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-7. Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 1.,  2.,  5.],\n",
       "         [ 3.,  0.,  7.]],\n",
       " \n",
       "        [[ 6.,  5.,  9.],\n",
       "         [ 4.,  8.,  3.]]]), (2, 2, 3))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([[[1., 2., 5.]\n",
    "               ,[3., 0., 7.]]\n",
    "              ,[[6., 5., 9.]\n",
    "                ,[4., 8., 3.]]\n",
    "             ])\n",
    "c, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(4, 3) dtype=float64>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(c, shape = [-1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  5.]\n",
      " [ 3.  0.  7.]\n",
      " [ 6.  5.  9.]\n",
      " [ 4.  8.  3.]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.reshape(c, shape = [-1, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_4:0' shape=(4, 1, 3) dtype=float64>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(c, shape = [-1, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.  2.  5.]]\n",
      "\n",
      " [[ 3.  0.  7.]]\n",
      "\n",
      " [[ 6.  5.  9.]]\n",
      "\n",
      " [[ 4.  8.  3.]]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.reshape(c, shape = [-1, 1, 3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-------------------------------------------------------------------------\n",
    "## 3. 상수 & 변수\n",
    "\n",
    "### tf.placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.3\n",
      "[  7.  10.]\n"
     ]
    }
   ],
   "source": [
    "## 상수 타입 정의\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "Y = a + b\n",
    "\n",
    "## tensorflow 실행\n",
    "sess = tf.Session()\n",
    "\n",
    "## 실행 시점에 상수 데이터 정의\n",
    "print(sess.run(Y, feed_dict = {a:8,     b:2.3}))\n",
    "print(sess.run(Y, feed_dict = {a:[2,3], b:[5,7]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Var_1/read:0\", shape=(784, 200), dtype=float32)\n",
      "Tensor(\"Variable_1/read:0\", shape=(200,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 변수 정의\n",
    "a = tf.Variable(tf.random_normal([784,200]), name = \"Var\")\n",
    "b = tf.Variable(tf.zeros([200]))\n",
    "\n",
    "print(a), print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------\n",
    "## 4. Linear Regression \n",
    "## 4-1) Single Variable \n",
    "\n",
    "## A. X, Y 데이터를 정의한 경우 (상수 정의 전)\n",
    "\n",
    "$ H(x) = Wx + b $\n",
    "\n",
    "### (1) Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## x, y 정의\n",
    "x_train = [1,2,3]\n",
    "y_train = [3,6,9]\n",
    "\n",
    "## weight, bias 정의\n",
    "W = tf.Variable(tf.random_normal([1]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")\n",
    "\n",
    "## model 정의\n",
    "model = x_train * W + b\n",
    "\n",
    "## loss function 정의(cost 최소화)\n",
    "cost = tf.reduce_mean(tf.square(model - y_train))\n",
    "\n",
    "## Gradient Descent (Gradient optimization)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Run Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Session option (Launch Graph in a session)\n",
    "sess = tf.Session()\n",
    "\n",
    "## 변수 초기화 (반드시 실행 필요!!)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Update Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.5805 [ 1.93201768] [ 0.18145368]\n",
      "20 0.0799366 [ 2.69240499] [ 0.48534253]\n",
      "40 0.0356063 [ 2.77448511] [ 0.49228135]\n",
      "60 0.0320029 [ 2.79152274] [ 0.47197852]\n",
      "80 0.0290624 [ 2.80193377] [ 0.45006692]\n",
      "100 0.0263949 [ 2.81130052] [ 0.42894086]\n",
      "120 0.0239722 [ 2.82017446] [ 0.40878451]\n",
      "140 0.021772 [ 2.82862592] [ 0.38957325]\n",
      "160 0.0197737 [ 2.83668017] [ 0.37126479]\n",
      "180 0.0179587 [ 2.84435558] [ 0.35381654]\n",
      "200 0.0163104 [ 2.85167003] [ 0.33718851]\n",
      "220 0.0148134 [ 2.85864139] [ 0.32134193]\n",
      "240 0.0134537 [ 2.86528444] [ 0.30624005]\n",
      "260 0.0122189 [ 2.87161565] [ 0.29184791]\n",
      "280 0.0110974 [ 2.87764931] [ 0.27813223]\n",
      "300 0.0100789 [ 2.88339949] [ 0.26506078]\n",
      "320 0.00915379 [ 2.8888793] [ 0.2526038]\n",
      "340 0.00831359 [ 2.89410138] [ 0.24073236]\n",
      "360 0.00755056 [ 2.89907813] [ 0.22941896]\n",
      "380 0.00685752 [ 2.90382099] [ 0.21863715]\n",
      "400 0.00622815 [ 2.90834117] [ 0.20836203]\n",
      "420 0.00565648 [ 2.91264868] [ 0.19856986]\n",
      "440 0.00513731 [ 2.91675377] [ 0.18923782]\n",
      "460 0.0046658 [ 2.92066646] [ 0.18034452]\n",
      "480 0.00423752 [ 2.92439461] [ 0.17186891]\n",
      "500 0.00384861 [ 2.92794776] [ 0.16379173]\n",
      "520 0.00349536 [ 2.93133402] [ 0.15609406]\n",
      "540 0.00317455 [ 2.93456101] [ 0.14875819]\n",
      "560 0.00288316 [ 2.93763614] [ 0.14176713]\n",
      "580 0.00261852 [ 2.94056726] [ 0.13510476]\n",
      "600 0.0023782 [ 2.94336033] [ 0.12875526]\n",
      "620 0.00215991 [ 2.94602227] [ 0.12270416]\n",
      "640 0.00196166 [ 2.94855905] [ 0.11693748]\n",
      "660 0.00178163 [ 2.95097661] [ 0.11144186]\n",
      "680 0.00161811 [ 2.95328045] [ 0.10620444]\n",
      "700 0.00146958 [ 2.95547581] [ 0.10121326]\n",
      "720 0.00133471 [ 2.95756817] [ 0.09645682]\n",
      "740 0.0012122 [ 2.95956302] [ 0.0919236]\n",
      "760 0.00110091 [ 2.96146321] [ 0.08760314]\n",
      "780 0.000999878 [ 2.96327448] [ 0.08348596]\n",
      "800 0.000908102 [ 2.96500039] [ 0.07956238]\n",
      "820 0.00082475 [ 2.96664548] [ 0.07582315]\n",
      "840 0.000749052 [ 2.96821284] [ 0.07225972]\n",
      "860 0.000680304 [ 2.96970654] [ 0.06886387]\n",
      "880 0.000617869 [ 2.97113037] [ 0.06562755]\n",
      "900 0.000561155 [ 2.97248697] [ 0.06254333]\n",
      "920 0.000509652 [ 2.97378039] [ 0.059604]\n",
      "940 0.000462871 [ 2.97501254] [ 0.05680274]\n",
      "960 0.00042038 [ 2.97618675] [ 0.05413315]\n",
      "980 0.000381803 [ 2.97730589] [ 0.05158903]\n",
      "1000 0.000346751 [ 2.97837257] [ 0.04916451]\n",
      "1020 0.000314929 [ 2.97938848] [ 0.04685405]\n",
      "1040 0.000286027 [ 2.98035741] [ 0.04465226]\n",
      "1060 0.000259769 [ 2.98128057] [ 0.04255372]\n",
      "1080 0.000235929 [ 2.98216033] [ 0.04055379]\n",
      "1100 0.00021428 [ 2.98299861] [ 0.03864793]\n",
      "1120 0.000194609 [ 2.98379779] [ 0.03683167]\n",
      "1140 0.000176746 [ 2.98455906] [ 0.03510071]\n",
      "1160 0.000160524 [ 2.98528481] [ 0.03345114]\n",
      "1180 0.00014579 [ 2.98597622] [ 0.03187907]\n",
      "1200 0.00013241 [ 2.98663521] [ 0.030381]\n",
      "1220 0.000120258 [ 2.98726344] [ 0.02895323]\n",
      "1240 0.000109215 [ 2.98786211] [ 0.02759251]\n",
      "1260 9.91964e-05 [ 2.98843217] [ 0.02629584]\n",
      "1280 9.00942e-05 [ 2.98897576] [ 0.02506012]\n",
      "1300 8.18235e-05 [ 2.98949385] [ 0.0238825]\n",
      "1320 7.43123e-05 [ 2.98998761] [ 0.02276022]\n",
      "1340 6.74955e-05 [ 2.99045825] [ 0.02169058]\n",
      "1360 6.12997e-05 [ 2.99090672] [ 0.02067119]\n",
      "1380 5.56716e-05 [ 2.99133396] [ 0.01969979]\n",
      "1400 5.05634e-05 [ 2.99174118] [ 0.018774]\n",
      "1420 4.59202e-05 [ 2.99212956] [ 0.01789171]\n",
      "1440 4.17067e-05 [ 2.99249935] [ 0.01705082]\n",
      "1460 3.78767e-05 [ 2.99285173] [ 0.01624949]\n",
      "1480 3.44031e-05 [ 2.99318767] [ 0.01548587]\n",
      "1500 3.12436e-05 [ 2.99350786] [ 0.01475814]\n",
      "1520 2.83753e-05 [ 2.99381304] [ 0.01406463]\n",
      "1540 2.57715e-05 [ 2.99410367] [ 0.01340359]\n",
      "1560 2.34092e-05 [ 2.99438071] [ 0.01277381]\n",
      "1580 2.12578e-05 [ 2.99464464] [ 0.0121735]\n",
      "1600 1.93072e-05 [ 2.99489641] [ 0.01160154]\n",
      "1620 1.75364e-05 [ 2.99513602] [ 0.01105648]\n",
      "1640 1.59283e-05 [ 2.99536467] [ 0.01053696]\n",
      "1660 1.44655e-05 [ 2.99558258] [ 0.01004187]\n",
      "1680 1.31382e-05 [ 2.99579024] [ 0.00956997]\n",
      "1700 1.1934e-05 [ 2.99598789] [ 0.00912036]\n",
      "1720 1.08381e-05 [ 2.99617648] [ 0.00869187]\n",
      "1740 9.84299e-06 [ 2.99635601] [ 0.00828343]\n",
      "1760 8.93887e-06 [ 2.99652719] [ 0.00789419]\n",
      "1780 8.11946e-06 [ 2.99669051] [ 0.00752328]\n",
      "1800 7.37386e-06 [ 2.99684572] [ 0.0071698]\n",
      "1820 6.69818e-06 [ 2.99699402] [ 0.006833]\n",
      "1840 6.08498e-06 [ 2.99713492] [ 0.00651206]\n",
      "1860 5.52486e-06 [ 2.99726987] [ 0.00620621]\n",
      "1880 5.01934e-06 [ 2.9973979] [ 0.00591465]\n",
      "1900 4.5587e-06 [ 2.99751997] [ 0.00563685]\n",
      "1920 4.14042e-06 [ 2.99763656] [ 0.00537211]\n",
      "1940 3.76066e-06 [ 2.99774766] [ 0.00511978]\n",
      "1960 3.4154e-06 [ 2.99785352] [ 0.0048793]\n",
      "1980 3.10206e-06 [ 2.99795437] [ 0.00465012]\n",
      "2000 2.81774e-06 [ 2.99805045] [ 0.00443172]\n",
      "2020 2.55949e-06 [ 2.99814177] [ 0.00422362]\n",
      "2040 2.32499e-06 [ 2.99822879] [ 0.00402534]\n",
      "2060 2.11126e-06 [ 2.998312] [ 0.0038363]\n",
      "2080 1.91772e-06 [ 2.99839115] [ 0.00365616]\n",
      "2100 1.74216e-06 [ 2.99846721] [ 0.00348463]\n",
      "2120 1.58295e-06 [ 2.99853873] [ 0.00332116]\n",
      "2140 1.43733e-06 [ 2.99860692] [ 0.00316531]\n",
      "2160 1.30566e-06 [ 2.99867272] [ 0.00301679]\n",
      "2180 1.18601e-06 [ 2.99873471] [ 0.00287544]\n",
      "2200 1.07709e-06 [ 2.99879384] [ 0.00274046]\n",
      "2220 9.78652e-07 [ 2.99885106] [ 0.00261202]\n",
      "2240 8.89549e-07 [ 2.99890423] [ 0.00248946]\n",
      "2260 8.07711e-07 [ 2.99895644] [ 0.00237272]\n",
      "2280 7.33814e-07 [ 2.9990046] [ 0.00226143]\n",
      "2300 6.66364e-07 [ 2.99905205] [ 0.00215537]\n",
      "2320 6.05608e-07 [ 2.99909568] [ 0.00205428]\n",
      "2340 5.50292e-07 [ 2.99913859] [ 0.00195814]\n",
      "2360 4.99688e-07 [ 2.99917865] [ 0.00186616]\n",
      "2380 4.54145e-07 [ 2.99921703] [ 0.00177886]\n",
      "2400 4.1207e-07 [ 2.99925423] [ 0.00169527]\n",
      "2420 3.74748e-07 [ 2.99928856] [ 0.00161581]\n",
      "2440 3.40527e-07 [ 2.99932194] [ 0.00154041]\n",
      "2460 3.09213e-07 [ 2.99935436] [ 0.001468]\n",
      "2480 2.81009e-07 [ 2.99938393] [ 0.00139917]\n",
      "2500 2.55322e-07 [ 2.99941254] [ 0.00133398]\n",
      "2520 2.31996e-07 [ 2.99944091] [ 0.00127144]\n",
      "2540 2.10587e-07 [ 2.99946666] [ 0.00121165]\n",
      "2560 1.91419e-07 [ 2.99949121] [ 0.00115505]\n",
      "2580 1.74115e-07 [ 2.99951506] [ 0.00110129]\n",
      "2600 1.57818e-07 [ 2.99953866] [ 0.00104956]\n",
      "2620 1.43348e-07 [ 2.99955988] [ 0.00100014]\n",
      "2640 1.30434e-07 [ 2.99958014] [ 0.0009534]\n",
      "2660 1.18756e-07 [ 2.99959922] [ 0.00090918]\n",
      "2680 1.07885e-07 [ 2.99961829] [ 0.00086699]\n",
      "2700 9.78954e-08 [ 2.99963689] [ 0.00082617]\n",
      "2720 8.89797e-08 [ 2.99965382] [ 0.00078719]\n",
      "2740 8.08151e-08 [ 2.99966955] [ 0.0007503]\n",
      "2760 7.348e-08 [ 2.99968457] [ 0.00071539]\n",
      "2780 6.67621e-08 [ 2.99969888] [ 0.00068247]\n",
      "2800 6.07103e-08 [ 2.99971318] [ 0.00065096]\n",
      "2820 5.5091e-08 [ 2.99972749] [ 0.00062043]\n",
      "2840 5.00799e-08 [ 2.99974036] [ 0.00059095]\n",
      "2860 4.55225e-08 [ 2.99975228] [ 0.00056306]\n",
      "2880 4.1265e-08 [ 2.99976373] [ 0.00053667]\n",
      "2900 3.75807e-08 [ 2.99977446] [ 0.0005117]\n",
      "2920 3.4161e-08 [ 2.99978471] [ 0.00048813]\n",
      "2940 3.12025e-08 [ 2.99979424] [ 0.00046578]\n",
      "2960 2.83463e-08 [ 2.99980378] [ 0.00044452]\n",
      "2980 2.57234e-08 [ 2.99981332] [ 0.00042398]\n",
      "3000 2.33189e-08 [ 2.99982285] [ 0.00040393]\n"
     ]
    }
   ],
   "source": [
    "## Fit the line\n",
    "for step in range(3001):\n",
    "    sess.run(optimizer)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------\n",
    "## 4-1) Single Variable\n",
    "## B. X, Y 데이터를 tf.placeholder로 정의한 경우 (상수 정의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.12552 [ 0.6470257] [-0.19217764]\n",
      "20 0.0103287 [ 0.97805756] [-0.04482184]\n",
      "40 0.000206191 [ 1.00902975] [-0.02954428]\n",
      "60 0.000104082 [ 1.01145637] [-0.02690169]\n",
      "80 9.37742e-05 [ 1.01118934] [-0.02551796]\n",
      "100 8.51608e-05 [ 1.0106895] [-0.02430728]\n",
      "120 7.73453e-05 [ 1.01018941] [-0.02316385]\n",
      "140 7.02445e-05 [ 1.00971079] [-0.02207511]\n",
      "160 6.37966e-05 [ 1.00925446] [-0.02103763]\n",
      "180 5.79419e-05 [ 1.00881958] [-0.02004892]\n",
      "200 5.26238e-05 [ 1.00840509] [-0.01910673]\n",
      "220 4.77944e-05 [ 1.00801015] [-0.01820882]\n",
      "240 4.34078e-05 [ 1.00763369] [-0.01735308]\n",
      "260 3.94232e-05 [ 1.00727499] [-0.01653757]\n",
      "280 3.58046e-05 [ 1.00693309] [-0.01576038]\n",
      "300 3.25187e-05 [ 1.00660717] [-0.01501974]\n",
      "320 2.95343e-05 [ 1.00629675] [-0.01431387]\n",
      "340 2.68232e-05 [ 1.00600076] [-0.0136412]\n",
      "360 2.43612e-05 [ 1.00571871] [-0.01300009]\n",
      "380 2.21259e-05 [ 1.00545013] [-0.01238916]\n",
      "400 2.00947e-05 [ 1.00519395] [-0.01180695]\n",
      "420 1.82506e-05 [ 1.00494981] [-0.01125208]\n",
      "440 1.65754e-05 [ 1.00471723] [-0.01072327]\n",
      "460 1.50543e-05 [ 1.0044955] [-0.01021934]\n",
      "480 1.36725e-05 [ 1.00428426] [-0.00973909]\n",
      "500 1.24174e-05 [ 1.00408292] [-0.0092814]\n",
      "520 1.12777e-05 [ 1.00389099] [-0.00884521]\n",
      "540 1.02429e-05 [ 1.00370824] [-0.00842953]\n",
      "560 9.30265e-06 [ 1.00353396] [-0.00803341]\n",
      "580 8.44877e-06 [ 1.0033679] [-0.0076559]\n",
      "600 7.67376e-06 [ 1.00320959] [-0.00729613]\n",
      "620 6.96956e-06 [ 1.00305879] [-0.00695325]\n",
      "640 6.32947e-06 [ 1.00291502] [-0.0066265]\n",
      "660 5.74876e-06 [ 1.00277805] [-0.00631509]\n",
      "680 5.22092e-06 [ 1.00264752] [-0.00601833]\n",
      "700 4.74201e-06 [ 1.00252318] [-0.00573554]\n",
      "720 4.30668e-06 [ 1.00240445] [-0.00546601]\n",
      "740 3.9118e-06 [ 1.00229156] [-0.00520916]\n",
      "760 3.55261e-06 [ 1.00218391] [-0.00496437]\n",
      "780 3.22649e-06 [ 1.00208139] [-0.00473113]\n",
      "800 2.9304e-06 [ 1.00198352] [-0.00450885]\n",
      "820 2.6617e-06 [ 1.00189042] [-0.00429701]\n",
      "840 2.41738e-06 [ 1.00180149] [-0.00409516]\n",
      "860 2.19568e-06 [ 1.00171685] [-0.00390276]\n",
      "880 1.99399e-06 [ 1.00163627] [-0.00371937]\n",
      "900 1.81121e-06 [ 1.00155926] [-0.00354465]\n",
      "920 1.64511e-06 [ 1.00148618] [-0.00337812]\n",
      "940 1.49408e-06 [ 1.00141621] [-0.00321942]\n",
      "960 1.35695e-06 [ 1.00134981] [-0.00306815]\n",
      "980 1.23256e-06 [ 1.00128651] [-0.00292405]\n",
      "1000 1.11948e-06 [ 1.00122607] [-0.00278676]\n",
      "1020 1.01682e-06 [ 1.00116837] [-0.00265592]\n",
      "1040 9.2354e-07 [ 1.00111353] [-0.00253121]\n",
      "1060 8.38848e-07 [ 1.0010612] [-0.00241232]\n",
      "1080 7.61886e-07 [ 1.00101137] [-0.00229903]\n",
      "1100 6.9203e-07 [ 1.00096381] [-0.00219108]\n",
      "1120 6.2849e-07 [ 1.00091851] [-0.00208819]\n",
      "1140 5.70871e-07 [ 1.00087559] [-0.00199019]\n",
      "1160 5.18629e-07 [ 1.00083458] [-0.00189677]\n",
      "1180 4.71167e-07 [ 1.00079548] [-0.00180772]\n",
      "1200 4.27836e-07 [ 1.00075805] [-0.00172286]\n",
      "1220 3.88648e-07 [ 1.00072229] [-0.00164204]\n",
      "1240 3.53025e-07 [ 1.00068867] [-0.00156499]\n",
      "1260 3.20676e-07 [ 1.00065637] [-0.00149151]\n",
      "1280 2.91288e-07 [ 1.00062537] [-0.00142161]\n",
      "1300 2.64602e-07 [ 1.0005964] [-0.00135492]\n",
      "1320 2.40459e-07 [ 1.00056803] [-0.00129137]\n",
      "1340 2.18431e-07 [ 1.00054181] [-0.00123088]\n",
      "1360 1.98406e-07 [ 1.00051618] [-0.00117312]\n",
      "1380 1.80261e-07 [ 1.00049222] [-0.0011182]\n",
      "1400 1.63699e-07 [ 1.00046885] [-0.00106571]\n",
      "1420 1.48749e-07 [ 1.00044715] [-0.00101578]\n",
      "1440 1.35073e-07 [ 1.00042582] [-0.00096815]\n",
      "1460 1.22787e-07 [ 1.00040627] [-0.00092273]\n",
      "1480 1.11571e-07 [ 1.00038719] [-0.00087965]\n",
      "1500 1.01317e-07 [ 1.00036883] [-0.00083832]\n",
      "1520 9.20451e-08 [ 1.00035191] [-0.0007991]\n",
      "1540 8.36323e-08 [ 1.00033522] [-0.00076179]\n",
      "1560 7.59811e-08 [ 1.00031936] [-0.00072595]\n",
      "1580 6.90585e-08 [ 1.00030482] [-0.00069201]\n",
      "1600 6.27536e-08 [ 1.00029051] [-0.00065979]\n",
      "1620 5.69988e-08 [ 1.00027645] [-0.0006288]\n",
      "1640 5.1759e-08 [ 1.00026381] [-0.00059928]\n",
      "1660 4.71036e-08 [ 1.00025177] [-0.00057136]\n",
      "1680 4.28225e-08 [ 1.00023985] [-0.00054479]\n",
      "1700 3.88252e-08 [ 1.00022829] [-0.00051915]\n",
      "1720 3.52736e-08 [ 1.0002178] [-0.00049474]\n",
      "1740 3.20683e-08 [ 1.00020778] [-0.00047166]\n",
      "1760 2.91676e-08 [ 1.00019825] [-0.00044978]\n",
      "1780 2.65018e-08 [ 1.00018871] [-0.00042883]\n",
      "1800 2.40516e-08 [ 1.00017965] [-0.00040857]\n",
      "1820 2.1866e-08 [ 1.0001713] [-0.00038934]\n",
      "1840 1.98676e-08 [ 1.00016356] [-0.00037115]\n",
      "1860 1.80686e-08 [ 1.00015604] [-0.00035394]\n",
      "1880 1.64539e-08 [ 1.00014889] [-0.00033761]\n",
      "1900 1.49355e-08 [ 1.00014174] [-0.00032196]\n",
      "1920 1.35636e-08 [ 1.00013471] [-0.00030676]\n",
      "1940 1.22965e-08 [ 1.00012839] [-0.0002922]\n",
      "1960 1.11721e-08 [ 1.00012255] [-0.00027843]\n",
      "1980 1.01532e-08 [ 1.00011694] [-0.00026542]\n",
      "2000 9.24364e-09 [ 1.00011158] [-0.00025312]\n",
      "2020 8.41613e-09 [ 1.00010657] [-0.00024148]\n",
      "2040 7.66258e-09 [ 1.0001018] [-0.00023045]\n",
      "2060 6.97176e-09 [ 1.00009704] [-0.00021992]\n",
      "2080 6.33697e-09 [ 1.00009227] [-0.00020972]\n",
      "2100 5.74232e-09 [ 1.00008762] [-0.00019973]\n",
      "2120 5.21395e-09 [ 1.00008345] [-0.00019015]\n",
      "2140 4.73166e-09 [ 1.00007951] [-0.00018108]\n",
      "2160 4.29204e-09 [ 1.00007582] [-0.00017251]\n",
      "2180 3.90379e-09 [ 1.00007236] [-0.0001644]\n",
      "2200 3.54178e-09 [ 1.00006902] [-0.00015672]\n",
      "2220 3.22703e-09 [ 1.00006592] [-0.00014946]\n",
      "2240 2.93209e-09 [ 1.00006306] [-0.00014262]\n",
      "2260 2.67755e-09 [ 1.0000602] [-0.00013613]\n",
      "2280 2.43797e-09 [ 1.00005758] [-0.00013]\n",
      "2300 2.22827e-09 [ 1.00005507] [-0.00012421]\n",
      "2320 2.03437e-09 [ 1.00005269] [-0.00011873]\n",
      "2340 1.85793e-09 [ 1.00005031] [-0.00011349]\n",
      "2360 1.6921e-09 [ 1.00004792] [-0.0001084]\n",
      "2380 1.53848e-09 [ 1.00004554] [-0.00010342]\n",
      "2400 1.39595e-09 [ 1.00004315] [ -9.85126171e-05]\n",
      "2420 1.25806e-09 [ 1.00004089] [ -9.36488796e-05]\n",
      "2440 1.13982e-09 [ 1.00003874] [ -8.89691219e-05]\n",
      "2460 1.0302e-09 [ 1.00003684] [ -8.45372997e-05]\n",
      "2480 9.25791e-10 [ 1.00003517] [ -8.03482835e-05]\n",
      "2500 8.42639e-10 [ 1.00003338] [ -7.63992648e-05]\n",
      "2520 7.5606e-10 [ 1.00003183] [ -7.26533108e-05]\n",
      "2540 6.8421e-10 [ 1.00003028] [ -6.91175519e-05]\n",
      "2560 6.19901e-10 [ 1.00002885] [ -6.57792843e-05]\n",
      "2580 5.64177e-10 [ 1.00002754] [ -6.26238252e-05]\n",
      "2600 5.11829e-10 [ 1.00002623] [ -5.96415994e-05]\n",
      "2620 4.64336e-10 [ 1.00002503] [ -5.68123651e-05]\n",
      "2640 4.21784e-10 [ 1.00002384] [ -5.41408881e-05]\n",
      "2660 3.84773e-10 [ 1.00002277] [ -5.16200162e-05]\n",
      "2680 3.48739e-10 [ 1.0000217] [ -4.92342442e-05]\n",
      "2700 3.16471e-10 [ 1.00002086] [ -4.69795959e-05]\n",
      "2720 2.88163e-10 [ 1.00001991] [ -4.48505234e-05]\n",
      "2740 2.65269e-10 [ 1.00001895] [ -4.28442290e-05]\n",
      "2760 2.43389e-10 [ 1.00001812] [ -4.09448294e-05]\n",
      "2780 2.20372e-10 [ 1.0000174] [ -3.91439789e-05]\n",
      "2800 2.04096e-10 [ 1.00001669] [ -3.74428637e-05]\n",
      "2820 1.85429e-10 [ 1.00001597] [ -3.58363141e-05]\n",
      "2840 1.72142e-10 [ 1.00001526] [ -3.43199645e-05]\n",
      "2860 1.57533e-10 [ 1.00001466] [ -3.28866699e-05]\n",
      "2880 1.42795e-10 [ 1.00001419] [ -3.15249017e-05]\n",
      "2900 1.32729e-10 [ 1.00001359] [ -3.02418084e-05]\n",
      "2920 1.2282e-10 [ 1.00001299] [ -2.90330245e-05]\n",
      "2940 1.1402e-10 [ 1.00001252] [ -2.78862317e-05]\n",
      "2960 1.04071e-10 [ 1.00001216] [ -2.67998385e-05]\n",
      "2980 9.74261e-11 [ 1.00001168] [ -2.57762313e-05]\n",
      "3000 9.01312e-11 [ 1.00001121] [ -2.48082524e-05]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd8VHXe9vHPN5NGIAklASItVEMXiEizN8RdsLAKKqAi\n2NC9LbvrPt5bHn323l3dVdcFC4oFLFi2iGtXQESKBAHpGJoECIQQOqT+nj9m8I4IZIBJzszker9e\n88qZM2dmrhzHi5NzzvyOOecQEZHoEuN1ABERCT2Vu4hIFFK5i4hEIZW7iEgUUrmLiEQhlbuISBRS\nuYuIRCGVu4hIFFK5i4hEoViv3jgtLc1lZmZ69fYiIhFp4cKFO5xz6VUt51m5Z2ZmkpOT49Xbi4hE\nJDPbGMxy2i0jIhKFVO4iIlFI5S4iEoVU7iIiUUjlLiIShVTuIiJRSOUuIhKFIq7c1xXs488frkKX\nBxQRObaIK/fPVm7n6ZlreWrmWq+jiIiErYgr91vObs3g7qfxl49X8+mKbV7HEREJSxFX7mbGI0O7\n0eW0VH4+dRFrtu31OpKISNiJuHIHSIzzMXFkL+rEx3LLyzkU7S/xOpKISFiJyHIHyEitw7MjepG/\n+xB3vvY1peUVXkcSEQkbEVvuAL1aNeB/rurKnLWF/OG9lV7HEREJG54N+RsqQ3s1Z+XWPUyavZ6s\npskM693S60giIp6L6C33w359WRZnt0/jN+8sY8GGnV7HERHxXFSUe6wvhvHDe9K8QRK3TVnI5l0H\nvY4kIuKpqCh3gNSkOJ4bmU1JWQVjXs7hQEmZ15FERDwTNeUO0K5xPZ4c3oOV+Xv4xVvfaIgCEam1\noqrcAc7PaswDA7N4b+lWxk/P9TqOiIgnIv5smaMZe04bVuXv5a+frKF9k2QGdmnqdSQRkRoVdVvu\n4B+i4I9XdaV7i/rc++ZiVuXv8TqSiEiNispyh8AQBSN6US8hljGTc9ipIQpEpBaJ2nIHaJKSyLMj\nerFtTzF3vLpQQxSISK0R1eUO0KNlA/50VVfmrdvJQ++u8DqOiEiNiMoDqke6qmdzVufv5dlZ68jK\nSOb6s1p5HUlEpFpF/Zb7Yb8cmMV5p6fzu3eWM39doddxRESqVZXlbmYvmNl2M1t2jMfNzJ40s1wz\n+8bMeoY+5qnzxRh/G9aDlo2SuP3Vr9m084DXkUREqk0wW+4vAQOP8/hlQPvAbSzw9KnHqh6pdeJ4\nfmQ2peUVjJmcw/5iDVEgItGpynJ3zs0CjjfU4hBgsvObB9Q3s4xQBQy1Nun1GH9dT9Zs28v9by2h\nokJDFIhI9AnFPvdmwKZK9/MC837EzMaaWY6Z5RQUFITgrU/OuR3S+T+DOvLBsnyenP6tZzlERKpL\njR5Qdc5NdM5lO+ey09PTa/Ktf2T0gNZc3bM5T3z6LR8s3eppFhGRUAtFuW8GWlS63zwwL6yZGX+4\nsgs9Wtbn3jeXsGKLhigQkegRinKfBowMnDXTB9jtnIuITeHEOB/P3tCL1DpxjJmcQ+G+Yq8jiYiE\nRDCnQr4OzAVON7M8MxttZreZ2W2BRd4H1gG5wHPAHdWWtho0Tklk4she7NhXzO2vfk1JmYYoEJHI\nZ15d0CI7O9vl5OR48t5H887izfx86mKG927J/1zZBTPzOpKIyI+Y2ULnXHZVy9WK4QeCMeSMZqzK\n38vTM9fSKSOZEX0zvY4kInLSas3wA8G4/5LTuTCrMf/33RXMWbvD6zgiIidN5V6JL8Z4YtgZZKbV\n5c5Xv+a7Qg1RICKRSeV+hORE/xAFFQ7GTM5hn4YoEJEIpHI/isy0uky4rie5Bfu4543FGqJARCKO\nyv0YBrRP478v78gnK7bxxKdrvI4jInJCdLbMcdzYL5OVW/fw5PRcOjRN5ifdTvM6kohIULTlfhxm\nxsNXdKFXqwbc/9YSlm3e7XUkEZGgqNyrkBDr45kbetEgKZ6xk3Mo2KshCkQk/Kncg5CenMBzI7PZ\neaCE219ZqCEKRCTsqdyD1KVZKo8O7U7OxiJ+8+9leDVsg4hIMHRA9QT8tPtprM7fy/gZuXTMSObG\n/q29jiQiclTacj9B917cgYs7NeHh91byZa6GKBCR8KRyP0ExMcbj155B2/S63P7KQlbn7/U6kojI\nj6jcT0K9hFgmjTqTxDgfIybNZ9NOjUEjIuFF5X6SWjRMYsroszhUWs6ISfN1iqSIhBWV+yk4vWky\nL97Um217ihn1wlfsOVTqdSQREUDlfsp6tWrA0zf0ZM22vdzycg6HSsu9jiQionIPhfNOb8xfr+nO\ngg07GffaIsrK9SUnEfGWyj1EhpzRjIcGd+bTldv41T+WaphgEfGUvsQUQiP6ZrJzfymPf7qGBklx\nPHh5R11oW0Q8oXIPsbsvbMfO/cU8P3s9DevFc8d57byOJCK1kMo9xMyM3/20M0UHSnnkw9U0SIpn\neO+WXscSkVpG5V4NYmKMv/ysO3sOlfLgv5aSWieOQV0zvI4lIrWIDqhWk/jYGJ6+vhc9Wjbgv6Yu\n1jg0IlKjVO7VqE68jxdGnUnrtLqMnZzDkk27vI4kIrVEUOVuZgPNbLWZ5ZrZA0d5vKWZzTCzRWb2\njZkNCn3UyJSaFMfk0b1pWC+eG1/8itzt+7yOJCK1QJXlbmY+YAJwGdAJGG5mnY5Y7L+BN51zPYBh\nwFOhDhrJmqQkMuXms/DFxDBi0nw27zrodSQRiXLBbLn3BnKdc+uccyXAVGDIEcs4ICUwnQpsCV3E\n6JCZVpeXbz6TfYfKGDFpPoX7NNCYiFSfYMq9GbCp0v28wLzKfg/cYGZ5wPvAXUd7ITMba2Y5ZpZT\nUFBwEnEjW+fTUnl+VDabiw5y00sL2Fdc5nUkEYlSoTqgOhx4yTnXHBgETDGzH722c26icy7bOZed\nnp4eoreOLGe1acSE63qyfMsexk7OobhMA42JSOgFU+6bgRaV7jcPzKtsNPAmgHNuLpAIpIUiYDS6\nqFMTHrm6G3PWFvLz1xdTrnFoRCTEgin3BUB7M2ttZvH4D5hOO2KZ74ALAcysI/5yr337XU7A1b2a\n85ufdOLD5fk8+K+lOKeCF5HQqfIbqs65MjMbB3wE+IAXnHPLzewhIMc5Nw24D3jOzO7Bf3D1Rqe2\nqtLoAa0p2l/C+Bm5NKgbz68GZnkdSUSiRFDDDzjn3sd/oLTyvN9Wml4B9A9ttNrhvks6sPNACU/P\nXEvDpHjGnNPG60giEgU0tozHzIyHh3Rh94FS/vD+SuonxfGz7BZVP1FE5DhU7mHAF2M8dm13dh8s\n5YF/+gcau6RzU69jiUgE09gyYSIh1sezI3rRpVkq415fxLx1hV5HEpEIpnIPI3UTYnnxxjNp2TCJ\nW17OYdnm3V5HEpEIpXIPMw3rxjNldG9S68Qx6oWvWFeggcZE5MSp3MNQRmodJo/ujQNGTPqK/N2H\nvI4kIhFG5R6m2qbX4+WberPrQAkjJs1n14ESryOJSARRuYexrs1TeW5UNhsLD3DTSws4UKKBxkQk\nOCr3MNevbRpPDu/Bkk27uO2Vrykpq/A6kohEAJV7BBjYpSl/vKors9YUcO+bGmhMRKqmLzFFiGvP\nbEnRgVL+9MEq6ifF8fCQLpiZ17FEJEyp3CPIbee2pWh/Cc/OWofPjN/9tDMxMSp4EfkxlXuEeeCy\nLMorHM/PXk9xWQV/uLIrPhW8iBxB5R5hzIwHL+9IYpyP8TNyKS6r4NGh3Yj16fCJiPwvlXsEMjPu\nv/R0EuNi+MvHayguK+eJa3sQH6uCFxE/lXsEG3dBexLjfPy/91ZSUraQ8df1JDHO53UsEQkD2tSL\ncLec3YaHh3Tm05XbGTM5h4MluuC2iKjco8KIvpk8cnU3Zufu4KaXvmJfsb7JKlLbqdyjxDVntuCJ\na89gwYYiRk6az55DpV5HEhEPqdyjyJAzmjF+eA+Wbt7N9c/Np2i/BhsTqa1U7lHmsq4ZPDuiF6u3\n7WX4c/PYsa/Y60gi4gGVexS6IKsJL4w6kw2F+7n22bkaD16kFlK5R6kB7dN4+abe5O8+xLUT55JX\ndMDrSCJSg1TuUeysNo2YcstZ7NxfwrXPzmNj4X6vI4lIDVG5R7meLRvw+pg+HCgp45pn55K7Xddk\nFakNVO61QJdmqUwd25fyCsewiXNZlb/H60giUs2CKnczG2hmq80s18weOMYy15jZCjNbbmavhTam\nnKrTmybzxq19iY2JYdjEeSzN2+11JBGpRlWWu5n5gAnAZUAnYLiZdTpimfbAr4H+zrnOwH9VQ1Y5\nRW3T6/HmrX2pGx/Ldc/PY+HGIq8jiUg1CWbLvTeQ65xb55wrAaYCQ45YZgwwwTlXBOCc2x7amBIq\nLRsl8eZtfWlUN54Rk+Yzb12h15FEpBoEU+7NgE2V7ucF5lXWAehgZl+a2TwzGxiqgBJ6zerX4Y1b\n+3Ja/Trc+OJXzFpT4HUkEQmxUB1QjQXaA+cBw4HnzKz+kQuZ2VgzyzGznIICFYqXmqQkMnVsHzIb\n1eWWl3P4bOU2ryOJSAgFU+6bgRaV7jcPzKssD5jmnCt1zq0H1uAv+x9wzk10zmU757LT09NPNrOE\nSFq9BKaO7UNWRjK3TlnI+0u3eh1JREIkmHJfALQ3s9ZmFg8MA6Ydscy/8W+1Y2Zp+HfTrAthTqkm\n9ZPieeWWs+jeoj7jXvuafy868t9tEYlEVZa7c64MGAd8BKwE3nTOLTezh8xscGCxj4BCM1sBzAB+\n4ZzTkboIkZIYx+Sbe3NW60bc8+Zi3ljwndeRROQUmXPOkzfOzs52OTk5nry3HN2h0nLGTlnIrDUF\nPDSkMyP7ZnodSUSOYGYLnXPZVS2nb6jK9xLjfDw3shcXdWzCb99ZzsRZa72OJCInSeUuP5AQ6+Pp\nG3pyedcM/uf9Vfzt02/x6q87ETl5sV4HkPAT54vhb8POICEuhsc/XcPW3Qd5+IouxPm0LSASKVTu\nclSxvhj+MrQ7p6XWYfyMXPKKDvLUDT1JSYzzOpqIBEGbYnJMMTHG/ZeeziNDuzFvXSFXPzWHTTt1\n0Q+RSKBylypdk92CyTf3ZtueQ1z51BwWb9rldSQRqYLKXYLSr10a/7yjH3XiYxg2cS4f6NusImFN\n5S5Ba9c4mX/d0Z+OGSnc8drXPPv5Wp1JIxKmVO5yQtLqJfD6mD4M6prBHz9Yxf/51zJKyyu8jiUi\nR9DZMnLCEuN8/H1YD1o1TOKpmWvJKzrAhOt1Jo1IONGWu5yUmBjjlwOzeOTqbsxdW8jQp+eQV6Qz\naUTChcpdTsk1Z7bg5Zt7s3X3Ia6YMIclOpNGJCyo3OWU9W+Xxj9v70diXAzXTpzLh8vyvY4kUuup\n3CUk2jfxn0mT1TSF219dyHOz1ulMGhEPqdwlZNKT/Vd2GtQlgz+8v5L//vcyynQmjYgndLaMhFRi\nnI+/D+9By0ZJPD1zLXlFBxl/XQ+SdSaNSI3SlruEXEyM8auBWfzpqq58mbuDnz0zl827DnodS6RW\nUblLtRnWuyUv3dSbzUUHuWLClyzN2+11JJFaQ+Uu1WpA+zT+cUc/4n0xXPPsXD5erjNpRGqCyl2q\nXYcmyfz7zv50aJrMra8sZNLs9TqTRqSaqdylRqQnJzB1TB8Gdm7Kw/9ZwW/fWa4zaUSqkcpdakyd\neB8TruvJree2Ycq8jdwyOYd9xWVexxKJSip3qVExMcavL+vIH6/qyhff7uCqp75kbcE+r2OJRB2V\nu3hieO+WTL65Nzv2lTD477N5d8kWryOJRBWVu3imf7s03rt7AFkZKdz1+iJ+984yisvKvY4lEhVU\n7uKpjNQ6TB3bhzFnt+bluRu55pm5GjpYJASCKnczG2hmq80s18weOM5yV5uZM7Ps0EWUaBfni+HB\nyzvxzA29WFewn8ufnM30Vdu8jiUS0aosdzPzAROAy4BOwHAz63SU5ZKBnwPzQx1SaoeBXZryn7sH\n0LxBHW5+KYdHPlyl0yVFTlIwW+69gVzn3DrnXAkwFRhylOUeBv4MHAphPqllWjWqyz9u78fw3i15\nauZarn9+Ptv36CMlcqKCKfdmwKZK9/MC875nZj2BFs6590KYTWqpxDgff7yqK49d051v8nYz6MnZ\nzF1b6HUskYhyygdUzSwGeAy4L4hlx5pZjpnlFBQUnOpbS5S7qmdz3hnXn5Q6sVz//DwmzMilokLD\nFogEI5hy3wy0qHS/eWDeYclAF2CmmW0A+gDTjnZQ1Tk30TmX7ZzLTk9PP/nUUmt0aJLMtHEDuLzb\naTz60WpGv7yAXQdKvI4lEvaCKfcFQHsza21m8cAwYNrhB51zu51zac65TOdcJjAPGOycy6mWxFLr\n1EuI5clhZ/DwkM7Mzt3B5U/OZrEuxC1yXFWWu3OuDBgHfASsBN50zi03s4fMbHB1BxQBMDNG9M3k\n7dv6AfCzZ+bw8pwNGl1S5BjMq/85srOzXU6ONu7lxO06UMK9by5h+qrtXN4tgz9f3Y16CbpipNQO\nZrbQOVfld4n0DVWJOPWT4nl+ZDa/HHg6HyzdyuC/z2ZV/h6vY4mEFZW7RKSYGOOO89rx2pg+7C0u\n44oJX/L2wjyvY4mEDZW7RLQ+bRrx3t0DOKNFfe5/awm/evsbDpVq8DERlbtEvMbJibwy+izuPL8t\nb+Rs4ooJX7Jyq3bTSO2mcpeoEOuL4ReXZvHijWeyY18xg8fPZsKMXI1NI7WWyl2iyvlZjfn4nnO5\nuFMTHv1oNVc/M5fc7brSk9Q+KneJOg3rxjPhup48ObwHG3bs5/Inv2DS7PUaukBqFZW7RCUzY3D3\n0/jknnMY0C6Nh/+zgmHPzeO7Ql0IRGoHlbtEtcYpiTw/KptHhnZjxZY9DPzbLF6dv1HfbJWop3KX\nqGdmXJPdgo/uOYeeLRvw4L+WMfKFr9i6+6DX0USqjcpdao1m9esw+ebePDykMzkbirjk8Vn8Y2Ge\ntuIlKqncpVaJifEPQPbBz88mq2ky9721hLFTFlKwt9jraCIhpXKXWikzrS5Tx/blwUEd+XxNAZc8\n/jnvfbPV61giIaNyl1rLF2OMOacN7989gBYNk7jzta+56/VFFO3XxUAk8qncpdZr1ziZf97ej/su\n7sAHS7dyyROz+HTFNq9jiZwSlbsI/uEL7rqwPe+M60+juvHcMjmHX7y1hD2HSr2OJnJSVO4ilXQ+\nLZV3xvXnzvPb8o+v87j4sc95d8kWnVEjEUflLnKEhFgfv7g0i3/e0Z+0egnc9foibpg0X2PUSERR\nuYscwxkt6jNt3AAeGtKZb/J2c9nfZvHnD1dxoKTM62giVVK5ixyHL8YY2TeTGfefx+DuzXh65lou\n+uvnfLhsq3bVSFhTuYsEIa1eAn+9pjtv3daXlDpx3PbK14x6cQHrd+z3OprIUancRU7AmZkN+c9d\nA/jtTzrx9cYiLn18Fn/9eDUHS3RpPwkvKneRExTri+HmAa2Zft+5DOralL9Pz+Xixz/nE50bL2FE\n5S5ykhqnJPLEsB5MHduHpHgfYybnMPqlBRozXsKCyl3kFPVp04j37j6bBwd1ZN66Qi56/HOe+HQN\nh0q1q0a8o3IXCYE4XwxjzmnDZ/edxyWdmvDEp99yyeOzmLFqu9fRpJYKqtzNbKCZrTazXDN74CiP\n32tmK8zsGzP7zMxahT6qSPhrmprI+Ot68uotZxHnM256aQE3vfgVK7fu8Tqa1DJVlruZ+YAJwGVA\nJ2C4mXU6YrFFQLZzrhvwNvBIqIOKRJL+7dL44Ofn8OvLsli4sYhBT37BvW8sZtNO7Y+XmhHMlntv\nINc5t845VwJMBYZUXsA5N8M5d/hTOw9oHtqYIpEnPjaGW89tyxe/vICx57ThvaVbufCvn/PQuyvY\nqWGFpZoFU+7NgE2V7ucF5h3LaOCDUwklEk1Sk+L49WUdmfmL87iyRzNemrOecx6ZwZOffcv+Yg1l\nINUjpAdUzewGIBt49BiPjzWzHDPLKSgoCOVbi4S9jNQ6/HloNz6+5xz6tW3EY5+s4dxHZzJl7gZK\nyyu8jidRJphy3wy0qHS/eWDeD5jZRcCDwGDn3FEvSOmcm+icy3bOZaenp59MXpGI165xMhNHZvOP\n2/vRJq0uv3lnORcFhhauqNB4NRIawZT7AqC9mbU2s3hgGDCt8gJm1gN4Fn+x69wvkSD0atWAN27t\nwws3ZlMnzsddry9i8ITZzP52h9fRJApUWe7OuTJgHPARsBJ40zm33MweMrPBgcUeBeoBb5nZYjOb\ndoyXE5FKzIwLsprw3t1n89g13SnaX8oNk+Zzw/PzWZq32+t4EsHMq2FLs7OzXU5OjifvLRKuisvK\neWXed4yf/i1FB0q5pFMT7jy/Hd1b1Pc6moQJM1vonMuucjmVu0j42XOolElfrOfFL9ez51AZA9ql\nccf5benbphFm5nU88ZDKXSQK7Csu49V5G3nui/Xs2FdMj5b1ufO8dlzYsbFKvpZSuYtEkUOl5by1\nMI9nZq5l866DZDVN5o7z23F51wx8MSr52kTlLhKFSssreHfJFp6auZbc7fvIbJTEbee25cqezUiI\n9XkdT2qAyl0kilVUOD5ekc+EGWtZunk3TVMSGXNOG4b3bkFSfKzX8aQaqdxFagHnHF98u4MJM3KZ\nv34nDZLiGNk3k+vPaknjlESv40k1ULmL1DI5G3by1My1TF+1nTifcVmXDEb1y6Rny/o6+BpFVO4i\ntdT6HfuZPHcDb+fksbe4jC7NUhjVN5Ofdj+NxDjtl490KneRWm5/cRn/XLSZyXM28O32fTRIimNY\n75bc0KcVzerX8TqenCSVu4gA/v3yc9cW8tKcDXy6chsAl3Rqysh+rfSlqAgUbLnrsLpIlDMz+rVL\no1+7NPKKDvDKvO+YuuA7Plyez+lNkhnWuwVDzmhGw7rxXkeVENKWu0gtdKi0nGlLtjBl7kaWbt5N\nnM+4qGMThvZqzrkd0on1hfRSDxJC2i0jIkFZuXUPby/M49+LNlO4v4T05ASu6tGMob2a075Jstfx\n5AgqdxE5IaXlFcxYtZ23F+YxfdV2yioc3VvUZ2iv5gzudhqpSXFeRxRU7iJyCnbsK+adxVt4K2cT\nq/L3Eh8bw8Udm/CTbhmcd3pj6sTrlEqvqNxF5JQ551i+xb/b5t0lWyjcX0JSvI8LOzbh8q4ZnHd6\nus6dr2EqdxEJqbLyCr5av5P/LN3Kh8vy2bm/hLrxPi7q1IRBXTM4t4OKviao3EWk2pSVVzBv3U7e\nW7qFD5flU3SglHoJsVzYsTEXd2rCOR3SSUnUPvrqoHIXkRpRWl7B3LWFvPfNVj5akc+uA6XExhi9\nWzfkgqzGXNSxCZlpdb2OGTVU7iJS48orHF9/V8RnK7czfdU21mzbB0Cb9Lpc1LEJF2Q1plerBsTp\nPPqTpnIXEc99V3iA6au28dmq7cxbV0hpuaNuvI8+bRrRv10aA9qn0b5xPQ2BcAJU7iISVvYVlzH7\n2wJm5+7gy9xC1u/YD0B6cgID2qXRr20j+rVL06BmVVC5i0hYyys6wJzcQmbn7mDO2h3s2FcCQLP6\ndcjObMCZmQ05M7Mh7RvXI0bXif2eyl1EIoZzjlX5e5m/rpAFG4tYsH4n2/cWA5BaJ47sVg04o0V9\nureoT7fmqdRPqr2DnGlUSBGJGGZGx4wUOmakcGP/1jjn2LTzIF9t2EnOhp0s2LCTz1Zt/375zEZJ\ndG9Rn67NUumUkcLpTZNpVC/Bw98g/KjcRSTsmBktGyXRslESQ3s1B2DPoVKW5u1mSd4ulmzaxfx1\nO3ln8Zbvn5OenEBW02ROb5JMVkYKWU2Tade4Xq39YlVQ5W5mA4G/AT7geefcn454PAGYDPQCCoFr\nnXMbQhtVRGqzlMQ4+rdLo3+7tO/nFewtZnX+Xlbl72FV/l5W5+9lyryNFJdVABBj0DqtLu0bJ9Mq\nLYnMRnVp1cj/s2lKYlTvy6+y3M3MB0wALgbygAVmNs05t6LSYqOBIudcOzMbBvwZuLY6AouIHJae\nnOA/26b9/xZ+eYVjQ+F+f+lv9Zf+t9v3Mn3VdkrKK75fLj42hlYNk2jVqC7N6ifSJDWRpin+2+Hp\nugmRu3MjmOS9gVzn3DoAM5sKDAEql/sQ4PeB6beB8WZmzqujtSJSa/lijLbp9WibXo9BXTO+n19e\n4di6+yAbCw+woXC//+cO/8/56wvZe6jsR6+VnBBL45QEmqQk0iApnvpJcf5bnXhSk+K+n1cvIZY6\ncT7qxPtIjPWRGB9DvC/G0/P3gyn3ZsCmSvfzgLOOtYxzrszMdgONgB2hCCkicqp8MUbzBkk0b5D0\ng107hx0oKSN/9yHy9xxi255D5O8uDvw8xPa9h1iZv4fdB0rZdbCU8opT22798L/OJqtpyim9RlVq\n9G8OMxsLjAVo2bJlTb61iMhxJcXH0ia9Hm3S6x13Oecc+4rL2HWglN0HSyk6UML+4jLGz8hl2eY9\nQb1XTQyqFky5bwZaVLrfPDDvaMvkmVkskIr/wOoPOOcmAhPBf577yQQWEfGSmZGcGEdyYtwPinFg\nl4xjPscLwYzeswBob2atzSweGAZMO2KZacCowPRQYLr2t4uIeKfKLffAPvRxwEf4T4V8wTm33Mwe\nAnKcc9OAScAUM8sFduL/B0BERDwS1D5359z7wPtHzPttpelDwM9CG01ERE6WBlUWEYlCKncRkSik\nchcRiUIqdxGRKKRyFxGJQp5drMPMCoCNIXipNCJjmINIyBkJGUE5Qy0SckZCRqiZnK2cc+lVLeRZ\nuYeKmeUEc1USr0VCzkjICMoZapGQMxIyQnjl1G4ZEZEopHIXEYlC0VDuE70OEKRIyBkJGUE5Qy0S\nckZCRgijnBG/z11ERH4sGrbcRUTkCGFb7mY20MxWm1mumT1wjGWuMbMVZrbczF6rNL/czBYHbkcO\nT1yjOc3s8UpZ1pjZrkqPjTKzbwO3UUc+N4xyhtP6bGlmM8xskZl9Y2aDKj3268DzVpvZpeGW0cwy\nzexgpXX5THVlDDJnKzP7LJBxppk1r/RYOH02j5ezRj6bZvaCmW03s2XHeNzM7MnA7/CNmfWs9FiN\nrcsfcM60GWsZAAADm0lEQVSF3Q3/0MJrgTZAPLAE6HTEMu2BRUCDwP3GlR7bFy45j1j+LvxDJgM0\nBNYFfjYITDcIt5zhtj7x79O8PTDdCdhQaXoJkAC0DryOL8wyZgLLwmhdvgWMCkxfAEwJx8/msXLW\n8GfzHKDnsf77AYOADwAD+gDza3pdHnkL1y337y/K7ZwrAQ5flLuyMcAE51wRgHNuew1nhOByVjYc\neD0wfSnwiXNuZ+B3+AQYGIY5a1IwOR1w+OKTqcCWwPQQYKpzrtg5tx7IDbxeOGWsScHk7ARMD0zP\nqPR4uH02j5WzxjjnZuG/VsWxDAEmO795QH0zy6Bm1+UPhGu5H+2i3M2OWKYD0MHMvjSzeWZWeYUl\nmllOYP4VHucE/H9a4t+iPPwhDfq5IXAqOSG81ufvgRvMLA//NQbuOoHnep0RoHVgd83nZnZ2NeQ7\nkZxLgKsC01cCyWbWKMjnhkNOqLnPZlWO9XvU5Lr8gXAt92DE4t81cx7+Lc3nzKx+4LFWzv8tseuA\nJ8ysrTcRf2AY8LZzrtzrIFU4Ws5wWp/DgZecc83x/yk8xczC7XN8rIxbgZbOuR7AvcBrZpZynNep\nbvcD55rZIuBc/NdCDsfP5/FyhtNnM6yE2/8UhwVzUe48YJpzrjTwZ/ga/GWPc25z4Oc6YCbQw8Oc\nhw3jh7s6TuS5p+pUcobb+hwNvBnIMxdIxD+eR02tz5POGNhlVBiYvxD/vuYO1ZAxqJzOuS3OuasC\n/9g8GJi3K5jnhknOmvxsVuVYv0dNrssfqokd+yd6w79Vvg7/7oHDB1k6H7HMQODlwHQa/j99GuE/\naJFQaf63HOfgYXXnDCyXBWwg8L0C978HWtYH8jYITDcMw5xhtT7xH7S6MTDdEf/+bAM688MDquuo\nngOqp5Ix/XAm/AcQN3v53zzw3zMmMP0H4KFw/GweJ2eNfTYD75HJsQ+oXs4PD6h+VdPr8keZauJN\nTnJFDsK/Nb4WeDAw7yFgcGDagMeAFcBSYFhgfr/A/SWBn6O9zBm4/3vgT0d57s34D/zlAjeFY85w\nW5/4D659GcizGLik0nMfDDxvNXBZuGUErgaWB+Z9DfzU43U5NFCIa4DnCRRluH02j5WzJj+b+P+a\n3QqU4t9rMBq4Dbgt8LgBEwK/w1Ig24t1Wfmmb6iKiEShcN3nLiIip0DlLiIShVTuIiJRSOUuIhKF\nVO4iIlFI5S4iEoVU7iIiUUjlLiIShf4/F/3+nWabA/IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x64be710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build Graph\n",
    "## X, Y 정의 (tf.placeholder)\n",
    "X = tf.placeholder(tf.float32, shape = [None])\n",
    "Y = tf.placeholder(tf.float32, shape = [None])\n",
    "\n",
    "## weight, bias 정의\n",
    "W = tf.Variable(tf.random_normal([1]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")\n",
    "\n",
    "## model 정의\n",
    "model = X *W  + b\n",
    "\n",
    "## loss function 정의(cost 최소화)\n",
    "cost = tf.reduce_mean(tf.square(model - Y))\n",
    "\n",
    "## Gradient Descent (Gradient optimization)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# Run Graph\n",
    "## Session option (Launch Graph in a session)\n",
    "sess = tf.Session()\n",
    "\n",
    "## 변수 초기화 (반드시 실행 필요!!)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# Update Graph\n",
    "## result set\n",
    "cost_list = []\n",
    "W_list    = []\n",
    "\n",
    "## Fit the line\n",
    "for step in range(3001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, optimizer], feed_dict = {X: [1,2,3], Y : [1,2,3]})\n",
    "    cost_list.append(cost_val)\n",
    "    W_list.append(W_val)\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)\n",
    "\n",
    "plt.plot(W_list, cost_list)        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------\n",
    "## 4-2) Multi Variables\n",
    "\n",
    "## A. 변수를 각각 정의한 경우\n",
    "\n",
    "$ H(x_{1}, x_{2}, x_{3}) = x_{1} * w_{1} + x_{2} * w_{2} + x_{3} * w_{3} + b $\n",
    "\n",
    "### (1) Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## x, y data 정의\n",
    "x1_data = [23.,   35.,  48.,  62.,  83.]\n",
    "x2_data = [38.,   46.,  59.,  74.,  95.]\n",
    "x3_data = [35.,   42.,  46.,  53.,  60.]\n",
    "y_data  = [110., 146., 198., 223., 257.]\n",
    "\n",
    "## x1, x2, x3, y 정의\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "Y  = tf.placeholder(tf.float32)\n",
    "\n",
    "## w1, w2, w3, b 정의\n",
    "w1 = tf.Variable(tf.random_normal([1]))\n",
    "w2 = tf.Variable(tf.random_normal([1]))\n",
    "w3 = tf.Variable(tf.random_normal([1]))\n",
    "b  = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "## model 정의\n",
    "model = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "\n",
    "## loss function 정의(cost 최소화)\n",
    "cost = tf.reduce_mean(tf.square(model - Y))\n",
    "\n",
    "## Gradient Descent (Gradient optimization)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2~3) Run & Update Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  41418.3 | Prediction:  [ 14.09157467   8.425807    -3.3481915  -12.62978458 -30.93039894]\n",
      "20 Cost:  166.366 | Prediction:  [ 127.67745209  153.81390381  178.93356323  213.42396545  255.25283813]\n",
      "40 Cost:  155.689 | Prediction:  [ 129.14404297  155.80194092  181.56510925  216.77156067  259.64071655]\n",
      "60 Cost:  154.026 | Prediction:  [ 128.96514893  155.68304443  181.55371094  216.84077454  259.87667847]\n",
      "80 Cost:  152.441 | Prediction:  [ 128.76667786  155.53678894  181.50466919  216.86126709  260.04736328]\n",
      "100 Cost:  150.928 | Prediction:  [ 128.57243347  155.39369202  181.45629883  216.88056946  260.21304321]\n",
      "120 Cost:  149.485 | Prediction:  [ 128.38270569  155.25411987  181.40914917  216.89945984  260.37475586]\n",
      "140 Cost:  148.107 | Prediction:  [ 128.19734192  155.11799622  181.36317444  216.91790771  260.53256226]\n",
      "160 Cost:  146.792 | Prediction:  [ 128.01623535  154.98521423  181.31832886  216.93589783  260.68649292]\n",
      "180 Cost:  145.537 | Prediction:  [ 127.83933258  154.85572815  181.2746582   216.95353699  260.83673096]\n",
      "200 Cost:  144.338 | Prediction:  [ 127.66648102  154.72941589  181.23202515  216.97073364  260.98330688]\n",
      "220 Cost:  143.194 | Prediction:  [ 127.497612    154.60627747  181.1905365   216.98756409  261.12634277]\n",
      "240 Cost:  142.101 | Prediction:  [ 127.3326416   154.48616028  181.15005493  217.0039978   261.26596069]\n",
      "260 Cost:  141.058 | Prediction:  [ 127.17146301  154.36903381  181.11061096  217.02006531  261.40209961]\n",
      "280 Cost:  140.062 | Prediction:  [ 127.01397705  154.25480652  181.07214355  217.0357666   261.53503418]\n",
      "300 Cost:  139.11 | Prediction:  [ 126.86011505  154.14341736  181.03469849  217.05111694  261.66470337]\n",
      "320 Cost:  138.201 | Prediction:  [ 126.70976257  154.0348053   180.99815369  217.06611633  261.79122925]\n",
      "340 Cost:  137.332 | Prediction:  [ 126.56285858  153.92887878  180.96257019  217.08079529  261.91464233]\n",
      "360 Cost:  136.502 | Prediction:  [ 126.41931915  153.8256073   180.92790222  217.09510803  262.03512573]\n",
      "380 Cost:  135.709 | Prediction:  [ 126.27906799  153.72492981  180.89411926  217.10914612  262.15264893]\n",
      "400 Cost:  134.951 | Prediction:  [ 126.14200592  153.6267395   180.8611908   217.12284851  262.26727295]\n",
      "420 Cost:  134.227 | Prediction:  [ 126.00806427  153.53102112  180.82910156  217.13623047  262.37921143]\n",
      "440 Cost:  133.534 | Prediction:  [ 125.87717438  153.43766785  180.79782104  217.14930725  262.48834229]\n",
      "460 Cost:  132.872 | Prediction:  [ 125.74927521  153.34669495  180.7673645   217.16210938  262.59484863]\n",
      "480 Cost:  132.239 | Prediction:  [ 125.62426758  153.25796509  180.73768616  217.17462158  262.69873047]\n",
      "500 Cost:  131.633 | Prediction:  [ 125.50211334  153.17150879  180.70880127  217.18687439  262.8001709 ]\n",
      "520 Cost:  131.054 | Prediction:  [ 125.38275146  153.08721924  180.68066406  217.19885254  262.89907837]\n",
      "540 Cost:  130.5 | Prediction:  [ 125.26605988  153.00505066  180.65324402  217.21054077  262.99554443]\n",
      "560 Cost:  129.969 | Prediction:  [ 125.15200806  152.92492676  180.62649536  217.22195435  263.08966064]\n",
      "580 Cost:  129.462 | Prediction:  [ 125.04053497  152.84683228  180.60046387  217.23312378  263.18151855]\n",
      "600 Cost:  128.976 | Prediction:  [ 124.93158722  152.77072144  180.57511902  217.24407959  263.27108765]\n",
      "620 Cost:  128.51 | Prediction:  [ 124.82508087  152.6965332   180.55044556  217.25479126  263.35855103]\n",
      "640 Cost:  128.065 | Prediction:  [ 124.72098541  152.6242218   180.52641296  217.26522827  263.44381714]\n",
      "660 Cost:  127.638 | Prediction:  [ 124.61921692  152.55375671  180.50300598  217.27546692  263.52697754]\n",
      "680 Cost:  127.229 | Prediction:  [ 124.5197525   152.4850769   180.48022461  217.28549194  263.6081543 ]\n",
      "700 Cost:  126.837 | Prediction:  [ 124.42249298  152.41816711  180.45803833  217.29525757  263.68731689]\n",
      "720 Cost:  126.461 | Prediction:  [ 124.32743073  152.35292053  180.43644714  217.30482483  263.76452637]\n",
      "740 Cost:  126.101 | Prediction:  [ 124.23447418  152.28939819  180.41543579  217.31420898  263.83984375]\n",
      "760 Cost:  125.756 | Prediction:  [ 124.14359283  152.22744751  180.39494324  217.323349    263.91329956]\n",
      "780 Cost:  125.424 | Prediction:  [ 124.05474091  152.16711426  180.37503052  217.33230591  263.98498535]\n",
      "800 Cost:  125.106 | Prediction:  [ 123.96788025  152.10832214  180.3556366   217.34107971  264.05493164]\n",
      "820 Cost:  124.801 | Prediction:  [ 123.88293457  152.05105591  180.33679199  217.34967041  264.12313843]\n",
      "840 Cost:  124.508 | Prediction:  [ 123.79986572  151.99526978  180.31842041  217.35806274  264.18960571]\n",
      "860 Cost:  124.227 | Prediction:  [ 123.71865082  151.94090271  180.30055237  217.36625671  264.2545166 ]\n",
      "880 Cost:  123.956 | Prediction:  [ 123.63922119  151.88796997  180.28318787  217.37431335  264.31777954]\n",
      "900 Cost:  123.696 | Prediction:  [ 123.56154633  151.83636475  180.26626587  217.38215637  264.37948608]\n",
      "920 Cost:  123.446 | Prediction:  [ 123.48557281  151.78614807  180.24983215  217.38987732  264.43966675]\n",
      "940 Cost:  123.206 | Prediction:  [ 123.41127777  151.73721313  180.23381042  217.39738464  264.49841309]\n",
      "960 Cost:  122.975 | Prediction:  [ 123.33862305  151.6895752   180.21826172  217.40478516  264.55566406]\n",
      "980 Cost:  122.752 | Prediction:  [ 123.26753998  151.64315796  180.20315552  217.4119873   264.61151123]\n",
      "1000 Cost:  122.538 | Prediction:  [ 123.19802094  151.59797668  180.18841553  217.41903687  264.66595459]\n",
      "1020 Cost:  122.332 | Prediction:  [ 123.13001251  151.55397034  180.17411804  217.42596436  264.71908569]\n",
      "1040 Cost:  122.133 | Prediction:  [ 123.06348419  151.51113892  180.16021729  217.43273926  264.77084351]\n",
      "1060 Cost:  121.941 | Prediction:  [ 122.99839783  151.46943665  180.14671326  217.43936157  264.8213501 ]\n",
      "1080 Cost:  121.757 | Prediction:  [ 122.93471527  151.42883301  180.13357544  217.44584656  264.87060547]\n",
      "1100 Cost:  121.578 | Prediction:  [ 122.87243652  151.38931274  180.12080383  217.45220947  264.91860962]\n",
      "1120 Cost:  121.406 | Prediction:  [ 122.81149292  151.35084534  180.1084137   217.45843506  264.96542358]\n",
      "1140 Cost:  121.24 | Prediction:  [ 122.75183868  151.31340027  180.09634399  217.46452332  265.0111084 ]\n",
      "1160 Cost:  121.08 | Prediction:  [ 122.69347382  151.27693176  180.08462524  217.47047424  265.05560303]\n",
      "1180 Cost:  120.925 | Prediction:  [ 122.63636017  151.2414856   180.07327271  217.47631836  265.09902954]\n",
      "1200 Cost:  120.775 | Prediction:  [ 122.58047485  151.20695496  180.06221008  217.48204041  265.1413269 ]\n",
      "1220 Cost:  120.63 | Prediction:  [ 122.52577972  151.17340088  180.05151367  217.4876709   265.18261719]\n",
      "1240 Cost:  120.489 | Prediction:  [ 122.47223663  151.14070129  180.04107666  217.4931488   265.22283936]\n",
      "1260 Cost:  120.353 | Prediction:  [ 122.41983795  151.1089325   180.0309906   217.49853516  265.26205444]\n",
      "1280 Cost:  120.222 | Prediction:  [ 122.36854553  151.07801819  180.02116394  217.50379944  265.30026245]\n",
      "1300 Cost:  120.094 | Prediction:  [ 122.31832886  151.04794312  180.01164246  217.50895691  265.33752441]\n",
      "1320 Cost:  119.97 | Prediction:  [ 122.26916504  151.01869202  180.00239563  217.51400757  265.37387085]\n",
      "1340 Cost:  119.85 | Prediction:  [ 122.22103882  150.99026489  179.99343872  217.51898193  265.40927124]\n",
      "1360 Cost:  119.733 | Prediction:  [ 122.17392731  150.96260071  179.98475647  217.52381897  265.44378662]\n",
      "1380 Cost:  119.62 | Prediction:  [ 122.12779236  150.93572998  179.97634888  217.52859497  265.47744751]\n",
      "1400 Cost:  119.51 | Prediction:  [ 122.08261108  150.90960693  179.96817017  217.53326416  265.51022339]\n",
      "1420 Cost:  119.403 | Prediction:  [ 122.03837585  150.88420105  179.96025085  217.5378418   265.54220581]\n",
      "1440 Cost:  119.299 | Prediction:  [ 121.99504852  150.85951233  179.95259094  217.54234314  265.57333374]\n",
      "1460 Cost:  119.197 | Prediction:  [ 121.95261383  150.83552551  179.94514465  217.54672241  265.60366821]\n",
      "1480 Cost:  119.098 | Prediction:  [ 121.91105652  150.81221008  179.93797302  217.55105591  265.63327026]\n",
      "1500 Cost:  119.002 | Prediction:  [ 121.87033844  150.7895813   179.93099976  217.55528259  265.66207886]\n",
      "1520 Cost:  118.908 | Prediction:  [ 121.83046722  150.76754761  179.92425537  217.55941772  265.69015503]\n",
      "1540 Cost:  118.817 | Prediction:  [ 121.79138184  150.74620056  179.91770935  217.56350708  265.71755981]\n",
      "1560 Cost:  118.727 | Prediction:  [ 121.75311279  150.72544861  179.91140747  217.56750488  265.74420166]\n",
      "1580 Cost:  118.64 | Prediction:  [ 121.71559143  150.70530701  179.90527344  217.57139587  265.77017212]\n",
      "1600 Cost:  118.554 | Prediction:  [ 121.67884827  150.6857605   179.8993988   217.57527161  265.79547119]\n",
      "1620 Cost:  118.471 | Prediction:  [ 121.6428299   150.66677856  179.89367676  217.57902527  265.82015991]\n",
      "1640 Cost:  118.389 | Prediction:  [ 121.60752869  150.64834595  179.88815308  217.5827179   265.84417725]\n",
      "1660 Cost:  118.309 | Prediction:  [ 121.57294464  150.63047791  179.88284302  217.58636475  265.86758423]\n",
      "1680 Cost:  118.231 | Prediction:  [ 121.53903198  150.61314392  179.87768555  217.5899353   265.89035034]\n",
      "1700 Cost:  118.154 | Prediction:  [ 121.50576782  150.59628296  179.87268066  217.59339905  265.9125061 ]\n",
      "1720 Cost:  118.079 | Prediction:  [ 121.47319031  150.57998657  179.8678894   217.59683228  265.93414307]\n",
      "1740 Cost:  118.005 | Prediction:  [ 121.44123077  150.56416321  179.86328125  217.60020447  265.9552002 ]\n",
      "1760 Cost:  117.933 | Prediction:  [ 121.40988922  150.54882812  179.85881042  217.60351562  265.97573853]\n",
      "1780 Cost:  117.862 | Prediction:  [ 121.37918091  150.53396606  179.85452271  217.60678101  265.99569702]\n",
      "1800 Cost:  117.792 | Prediction:  [ 121.34903717  150.51956177  179.85038757  217.60997009  266.0151062 ]\n",
      "1820 Cost:  117.723 | Prediction:  [ 121.31947327  150.50561523  179.84638977  217.61309814  266.0340271 ]\n",
      "1840 Cost:  117.656 | Prediction:  [ 121.29049683  150.49211121  179.84255981  217.61616516  266.05245972]\n",
      "1860 Cost:  117.589 | Prediction:  [ 121.26204681  150.47900391  179.83886719  217.6191864   266.07037354]\n",
      "1880 Cost:  117.524 | Prediction:  [ 121.23415375  150.46633911  179.83532715  217.62216187  266.08782959]\n",
      "1900 Cost:  117.46 | Prediction:  [ 121.20678711  150.4540863   179.83192444  217.62507629  266.1048584 ]\n",
      "1920 Cost:  117.396 | Prediction:  [ 121.17992401  150.44224548  179.8286438   217.62794495  266.12136841]\n",
      "1940 Cost:  117.333 | Prediction:  [ 121.15357208  150.43077087  179.82553101  217.63078308  266.13745117]\n",
      "1960 Cost:  117.272 | Prediction:  [ 121.12770844  150.41967773  179.82250977  217.63354492  266.15313721]\n",
      "1980 Cost:  117.211 | Prediction:  [ 121.10231018  150.40895081  179.8196106   217.63626099  266.16833496]\n",
      "2000 Cost:  117.151 | Prediction:  [ 121.07738495  150.39859009  179.81686401  217.63891602  266.18319702]\n",
      "2020 Cost:  117.091 | Prediction:  [ 121.05291748  150.38861084  179.81425476  217.6415863   266.19763184]\n",
      "2040 Cost:  117.033 | Prediction:  [ 121.02888489  150.37893677  179.8117218   217.64414978  266.21166992]\n",
      "2060 Cost:  116.975 | Prediction:  [ 121.00530243  150.36961365  179.80932617  217.646698    266.22531128]\n",
      "2080 Cost:  116.918 | Prediction:  [ 120.98213959  150.36062622  179.80705261  217.6492157   266.23858643]\n",
      "2100 Cost:  116.861 | Prediction:  [ 120.9593811   150.35195923  179.80488586  217.65167236  266.25146484]\n",
      "2120 Cost:  116.805 | Prediction:  [ 120.93702698  150.34358215  179.80281067  217.65409851  266.2640686 ]\n",
      "2140 Cost:  116.749 | Prediction:  [ 120.91506958  150.33554077  179.80084229  217.65647888  266.27624512]\n",
      "2160 Cost:  116.694 | Prediction:  [ 120.89350891  150.32777405  179.79899597  217.65882874  266.28808594]\n",
      "2180 Cost:  116.64 | Prediction:  [ 120.87231445  150.32029724  179.79721069  217.66113281  266.29962158]\n",
      "2200 Cost:  116.586 | Prediction:  [ 120.85148621  150.31312561  179.79554749  217.66342163  266.31085205]\n",
      "2220 Cost:  116.533 | Prediction:  [ 120.83101654  150.30621338  179.79397583  217.66564941  266.32171631]\n",
      "2240 Cost:  116.48 | Prediction:  [ 120.8108902   150.29956055  179.79248047  217.66783142  266.33233643]\n",
      "2260 Cost:  116.427 | Prediction:  [ 120.79113007  150.29321289  179.79112244  217.6700592   266.34262085]\n",
      "2280 Cost:  116.375 | Prediction:  [ 120.77168274  150.28707886  179.78981018  217.67218018  266.35263062]\n",
      "2300 Cost:  116.324 | Prediction:  [ 120.75255585  150.28120422  179.78858948  217.67427063  266.36233521]\n",
      "2320 Cost:  116.272 | Prediction:  [ 120.73376465  150.27558899  179.78746033  217.67634583  266.3717041 ]\n",
      "2340 Cost:  116.221 | Prediction:  [ 120.715271    150.2702179   179.78642273  217.6783905   266.38088989]\n",
      "2360 Cost:  116.171 | Prediction:  [ 120.69708252  150.26504517  179.78543091  217.68041992  266.38977051]\n",
      "2380 Cost:  116.121 | Prediction:  [ 120.67919922  150.26013184  179.7845459   217.68238831  266.39840698]\n",
      "2400 Cost:  116.071 | Prediction:  [ 120.66159821  150.25543213  179.78372192  217.68434143  266.40679932]\n",
      "2420 Cost:  116.021 | Prediction:  [ 120.64427185  150.25094604  179.7829895   217.6862793   266.41488647]\n",
      "2440 Cost:  115.972 | Prediction:  [ 120.62723541  150.24667358  179.78231812  217.68817139  266.42279053]\n",
      "2460 Cost:  115.923 | Prediction:  [ 120.61045074  150.24261475  179.78170776  217.69003296  266.43041992]\n",
      "2480 Cost:  115.874 | Prediction:  [ 120.59394836  150.23873901  179.78118896  217.69189453  266.43783569]\n",
      "2500 Cost:  115.826 | Prediction:  [ 120.57769775  150.2350769   179.7807312   217.69372559  266.44500732]\n",
      "2520 Cost:  115.778 | Prediction:  [ 120.56169128  150.2315979   179.78031921  217.69552612  266.45199585]\n",
      "2540 Cost:  115.73 | Prediction:  [ 120.54593658  150.228302    179.77996826  217.69728088  266.45874023]\n",
      "2560 Cost:  115.682 | Prediction:  [ 120.53041077  150.22520447  179.77972412  217.6990509   266.465271  ]\n",
      "2580 Cost:  115.635 | Prediction:  [ 120.51512146  150.22227478  179.77949524  217.70075989  266.47161865]\n",
      "2600 Cost:  115.588 | Prediction:  [ 120.50006866  150.21949768  179.77934265  217.70246887  266.47781372]\n",
      "2620 Cost:  115.541 | Prediction:  [ 120.48523712  150.2169342   179.77926636  217.7041626   266.48373413]\n",
      "2640 Cost:  115.494 | Prediction:  [ 120.47061157  150.21450806  179.77920532  217.70581055  266.48947144]\n",
      "2660 Cost:  115.448 | Prediction:  [ 120.45619202  150.2122345   179.77922058  217.7074585   266.49505615]\n",
      "2680 Cost:  115.401 | Prediction:  [ 120.44199371  150.21012878  179.77929688  217.70907593  266.50045776]\n",
      "2700 Cost:  115.355 | Prediction:  [ 120.4280014   150.20819092  179.7794342   217.7106781   266.50567627]\n",
      "2720 Cost:  115.309 | Prediction:  [ 120.41418457  150.20640564  179.77960205  217.71224976  266.51071167]\n",
      "2740 Cost:  115.263 | Prediction:  [ 120.40058136  150.20475769  179.77984619  217.71383667  266.51559448]\n",
      "2760 Cost:  115.218 | Prediction:  [ 120.38716125  150.20324707  179.78009033  217.71536255  266.52032471]\n",
      "2780 Cost:  115.172 | Prediction:  [ 120.37393188  150.20185852  179.78042603  217.71688843  266.52490234]\n",
      "2800 Cost:  115.127 | Prediction:  [ 120.36086273  150.20062256  179.78079224  217.71838379  266.52929688]\n",
      "2820 Cost:  115.082 | Prediction:  [ 120.34797668  150.19953918  179.78118896  217.71987915  266.53353882]\n",
      "2840 Cost:  115.037 | Prediction:  [ 120.33527374  150.19857788  179.78166199  217.72135925  266.53762817]\n",
      "2860 Cost:  114.992 | Prediction:  [ 120.32272339  150.19770813  179.78215027  217.72280884  266.54156494]\n",
      "2880 Cost:  114.947 | Prediction:  [ 120.31034851  150.19700623  179.78269958  217.72424316  266.54537964]\n",
      "2900 Cost:  114.903 | Prediction:  [ 120.29812622  150.19639587  179.78327942  217.72567749  266.54907227]\n",
      "2920 Cost:  114.858 | Prediction:  [ 120.28606415  150.19590759  179.78390503  217.7270813   266.55258179]\n",
      "2940 Cost:  114.814 | Prediction:  [ 120.27414703  150.19552612  179.78456116  217.72846985  266.55599976]\n",
      "2960 Cost:  114.769 | Prediction:  [ 120.26238251  150.19529724  179.78526306  217.72987366  266.55926514]\n",
      "2980 Cost:  114.725 | Prediction:  [ 120.25077057  150.19514465  179.78601074  217.73123169  266.56240845]\n",
      "3000 Cost:  114.681 | Prediction:  [ 120.23928833  150.19508362  179.78677368  217.73257446  266.56546021]\n"
     ]
    }
   ],
   "source": [
    "## Session option (Launch Graph in a session)\n",
    "sess = tf.Session()\n",
    "\n",
    "## 변수 초기화 (반드시 실행 필요!!)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "## Fit the line\n",
    "for step in range(3001):\n",
    "    cost_val, model_val, _ = sess.run([cost, model, optimizer]\n",
    "                                      , feed_dict = {x1:x1_data, x2:x2_data, x3:x3_data, Y:y_data})\n",
    "    if step % 20 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"| Prediction: \", model_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------------------------------------------------------------------------------------------\n",
    "## 4-2) Multi Variables\n",
    "\n",
    "## B. X, Y matrix 곱으로 정의한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  41161.2 | W:  [[-0.34247261]\n",
      " [ 1.31231213]\n",
      " [ 0.72936344]\n",
      " [ 0.76242685]\n",
      " [-0.94039047]] | Prediction:  [[-17.31612778]\n",
      " [-14.72752762]\n",
      " [  7.95966005]]\n",
      "20 Cost:  3365.83 | W:  [[ 0.07205261]\n",
      " [ 1.77315784]\n",
      " [ 1.1986208 ]\n",
      " [ 1.27859759]\n",
      " [-0.40336505]] | Prediction:  [[ 166.50390625]\n",
      " [ 210.66339111]\n",
      " [ 174.87539673]]\n",
      "40 Cost:  3107.1 | W:  [[ 0.21372584]\n",
      " [ 1.88791263]\n",
      " [ 1.23851395]\n",
      " [ 1.26505113]\n",
      " [-0.53206909]] | Prediction:  [[ 164.19706726]\n",
      " [ 210.48612976]\n",
      " [ 178.08183289]]\n",
      "60 Cost:  2868.37 | W:  [[ 0.34960961]\n",
      " [ 1.99804127]\n",
      " [ 1.27666438]\n",
      " [ 1.25180054]\n",
      " [-0.65604067]] | Prediction:  [[ 161.89390564]\n",
      " [ 210.2097168 ]\n",
      " [ 181.08514404]]\n",
      "80 Cost:  2648.1 | W:  [[ 0.48005763]\n",
      " [ 2.10388637]\n",
      " [ 1.31334126]\n",
      " [ 1.23908293]\n",
      " [-0.77515161]] | Prediction:  [[ 159.6816864 ]\n",
      " [ 209.94393921]\n",
      " [ 183.97009277]]\n",
      "100 Cost:  2444.85 | W:  [[ 0.60528433]\n",
      " [ 2.20561767]\n",
      " [ 1.34860241]\n",
      " [ 1.22687721]\n",
      " [-0.88959306]] | Prediction:  [[ 157.55685425]\n",
      " [ 209.68844604]\n",
      " [ 186.74143982]]\n",
      "120 Cost:  2257.3 | W:  [[ 0.7254957 ]\n",
      " [ 2.30339599]\n",
      " [ 1.38250411]\n",
      " [ 1.21516335]\n",
      " [-0.99954915]] | Prediction:  [[ 155.51594543]\n",
      " [ 209.44277954]\n",
      " [ 189.40357971]]\n",
      "140 Cost:  2084.26 | W:  [[ 0.84088957]\n",
      " [ 2.39737797]\n",
      " [ 1.41509962]\n",
      " [ 1.20392215]\n",
      " [-1.10519671]] | Prediction:  [[ 153.55570984]\n",
      " [ 209.20661926]\n",
      " [ 191.96089172]]\n",
      "160 Cost:  1924.59 | W:  [[ 0.95165592]\n",
      " [ 2.4877131 ]\n",
      " [ 1.44644058]\n",
      " [ 1.19313455]\n",
      " [-1.20670581]] | Prediction:  [[ 151.6729126 ]\n",
      " [ 208.97952271]\n",
      " [ 194.41746521]]\n",
      "180 Cost:  1777.25 | W:  [[ 1.05797732]\n",
      " [ 2.57454467]\n",
      " [ 1.47657633]\n",
      " [ 1.18278301]\n",
      " [-1.30423903]] | Prediction:  [[ 149.86451721]\n",
      " [ 208.76118469]\n",
      " [ 196.77729797]]\n",
      "200 Cost:  1641.3 | W:  [[ 1.16002941]\n",
      " [ 2.6580112 ]\n",
      " [ 1.50555456]\n",
      " [ 1.17285025]\n",
      " [-1.39795399]] | Prediction:  [[ 148.12756348]\n",
      " [ 208.55126953]\n",
      " [ 199.04420471]]\n",
      "220 Cost:  1515.87 | W:  [[ 1.25797999]\n",
      " [ 2.73824549]\n",
      " [ 1.53342104]\n",
      " [ 1.16331947]\n",
      " [-1.48800063]] | Prediction:  [[ 146.45930481]\n",
      " [ 208.34936523]\n",
      " [ 201.22180176]]\n",
      "240 Cost:  1400.12 | W:  [[ 1.35199118]\n",
      " [ 2.81537437]\n",
      " [ 1.56021905]\n",
      " [ 1.15417516]\n",
      " [-1.57452369]] | Prediction:  [[ 144.85694885]\n",
      " [ 208.15525818]\n",
      " [ 203.31362915]]\n",
      "260 Cost:  1293.32 | W:  [[ 1.44221818]\n",
      " [ 2.88952041]\n",
      " [ 1.58599079]\n",
      " [ 1.14540184]\n",
      " [-1.65766191]] | Prediction:  [[ 143.31799316]\n",
      " [ 207.96855164]\n",
      " [ 205.32315063]]\n",
      "280 Cost:  1194.77 | W:  [[ 1.52881038]\n",
      " [ 2.96080184]\n",
      " [ 1.61077738]\n",
      " [ 1.13698494]\n",
      " [-1.73754895]] | Prediction:  [[ 141.83982849]\n",
      " [ 207.78901672]\n",
      " [ 207.25354004]]\n",
      "300 Cost:  1103.84 | W:  [[ 1.6119113 ]\n",
      " [ 3.02933049]\n",
      " [ 1.63461673]\n",
      " [ 1.1289103 ]\n",
      " [-1.81431293]] | Prediction:  [[ 140.42008972]\n",
      " [ 207.61631775]\n",
      " [ 209.10784912]]\n",
      "320 Cost:  1019.93 | W:  [[ 1.69165874]\n",
      " [ 3.09521556]\n",
      " [ 1.65754664]\n",
      " [ 1.12116444]\n",
      " [-1.88807678]] | Prediction:  [[ 139.05656433]\n",
      " [ 207.45024109]\n",
      " [ 210.88920593]]\n",
      "340 Cost:  942.509 | W:  [[ 1.76818466]\n",
      " [ 3.15856123]\n",
      " [ 1.67960262]\n",
      " [ 1.11373472]\n",
      " [-1.9589591 ]] | Prediction:  [[ 137.74691772]\n",
      " [ 207.2905426 ]\n",
      " [ 212.60044861]]\n",
      "360 Cost:  871.068 | W:  [[ 1.84161675]\n",
      " [ 3.21946716]\n",
      " [ 1.70081937]\n",
      " [ 1.10660827]\n",
      " [-2.02707338]] | Prediction:  [[ 136.48907471]\n",
      " [ 207.13684082]\n",
      " [ 214.24427795]]\n",
      "380 Cost:  805.147 | W:  [[ 1.91207623]\n",
      " [ 3.27803016]\n",
      " [ 1.72123015]\n",
      " [ 1.09977281]\n",
      " [-2.09252858]] | Prediction:  [[ 135.2809906 ]\n",
      " [ 206.98899841]\n",
      " [ 215.82341003]]\n",
      "400 Cost:  744.319 | W:  [[ 1.97968137]\n",
      " [ 3.33434129]\n",
      " [ 1.7408663 ]\n",
      " [ 1.09321773]\n",
      " [-2.15542936]] | Prediction:  [[ 134.12072754]\n",
      " [ 206.84686279]\n",
      " [ 217.34043884]]\n",
      "420 Cost:  688.191 | W:  [[ 2.04454398]\n",
      " [ 3.38849092]\n",
      " [ 1.75975847]\n",
      " [ 1.08693135]\n",
      " [-2.21587682]] | Prediction:  [[ 133.00634766]\n",
      " [ 206.71005249]\n",
      " [ 218.79768372]]\n",
      "440 Cost:  636.399 | W:  [[ 2.10677242]\n",
      " [ 3.4405632 ]\n",
      " [ 1.77793598]\n",
      " [ 1.08090329]\n",
      " [-2.2739675 ]] | Prediction:  [[ 131.93606567]\n",
      " [ 206.57839966]\n",
      " [ 220.19758606]]\n",
      "460 Cost:  588.607 | W:  [[ 2.166471  ]\n",
      " [ 3.49063969]\n",
      " [ 1.79542708]\n",
      " [ 1.07512355]\n",
      " [-2.32979465]] | Prediction:  [[ 130.90814209]\n",
      " [ 206.45176697]\n",
      " [ 221.54243469]]\n",
      "480 Cost:  544.508 | W:  [[ 2.22373962]\n",
      " [ 3.53879952]\n",
      " [ 1.81225848]\n",
      " [ 1.0695821 ]\n",
      " [-2.38344693]] | Prediction:  [[ 129.9209137 ]\n",
      " [ 206.32995605]\n",
      " [ 222.83433533]]\n",
      "500 Cost:  503.814 | W:  [[ 2.27867389]\n",
      " [ 3.58511853]\n",
      " [ 1.82845652]\n",
      " [ 1.06426942]\n",
      " [-2.43501019]] | Prediction:  [[ 128.97277832]\n",
      " [ 206.21270752]\n",
      " [ 224.07543945]]\n",
      "520 Cost:  466.264 | W:  [[ 2.33136535]\n",
      " [ 3.62966871]\n",
      " [ 1.84404624]\n",
      " [ 1.05917645]\n",
      " [-2.48456693]] | Prediction:  [[ 128.0622406 ]\n",
      " [ 206.09985352]\n",
      " [ 225.26768494]]\n",
      "540 Cost:  431.613 | W:  [[ 2.38190389]\n",
      " [ 3.67251968]\n",
      " [ 1.85905099]\n",
      " [ 1.05429494]\n",
      " [-2.53219628]] | Prediction:  [[ 127.18772125]\n",
      " [ 205.9912262 ]\n",
      " [ 226.41304016]]\n",
      "560 Cost:  399.637 | W:  [[ 2.43037343]\n",
      " [ 3.71373868]\n",
      " [ 1.87349415]\n",
      " [ 1.04961586]\n",
      " [-2.5779736 ]] | Prediction:  [[ 126.34779358]\n",
      " [ 205.88670349]\n",
      " [ 227.5133667 ]]\n",
      "580 Cost:  370.132 | W:  [[ 2.47685504]\n",
      " [ 3.75338984]\n",
      " [ 1.88739812]\n",
      " [ 1.04513144]\n",
      " [-2.62197232]] | Prediction:  [[ 125.54121399]\n",
      " [ 205.78607178]\n",
      " [ 228.57035828]]\n",
      "600 Cost:  342.904 | W:  [[ 2.52142787]\n",
      " [ 3.79153514]\n",
      " [ 1.9007839 ]\n",
      " [ 1.0408349 ]\n",
      " [-2.66426301]] | Prediction:  [[ 124.7665863 ]\n",
      " [ 205.68919373]\n",
      " [ 229.58581543]]\n",
      "620 Cost:  317.779 | W:  [[ 2.56416798]\n",
      " [ 3.82823348]\n",
      " [ 1.91367161]\n",
      " [ 1.03671765]\n",
      " [-2.70491219]] | Prediction:  [[ 124.02262878]\n",
      " [ 205.59594727]\n",
      " [ 230.56132507]]\n",
      "640 Cost:  294.593 | W:  [[ 2.60514641]\n",
      " [ 3.86354208]\n",
      " [ 1.9260813 ]\n",
      " [ 1.03277338]\n",
      " [-2.7439847 ]] | Prediction:  [[ 123.30825043]\n",
      " [ 205.50617981]\n",
      " [ 231.49848938]]\n",
      "660 Cost:  273.197 | W:  [[ 2.64443374]\n",
      " [ 3.89751601]\n",
      " [ 1.93803144]\n",
      " [ 1.02899468]\n",
      " [-2.78154373]] | Prediction:  [[ 122.62208557]\n",
      " [ 205.41970825]\n",
      " [ 232.39877319]]\n",
      "680 Cost:  253.452 | W:  [[ 2.68209672]\n",
      " [ 3.93020701]\n",
      " [ 1.94954026]\n",
      " [ 1.02537537]\n",
      " [-2.81764746]] | Prediction:  [[ 121.96321106]\n",
      " [ 205.33647156]\n",
      " [ 233.26367188]]\n",
      "700 Cost:  235.23 | W:  [[ 2.71819925]\n",
      " [ 3.96166658]\n",
      " [ 1.96062517]\n",
      " [ 1.021909  ]\n",
      " [-2.85235429]] | Prediction:  [[ 121.33045197]\n",
      " [ 205.25628662]\n",
      " [ 234.09458923]]\n",
      "720 Cost:  218.414 | W:  [[ 2.75280213]\n",
      " [ 3.99194312]\n",
      " [ 1.97130322]\n",
      " [ 1.01858926]\n",
      " [-2.88571882]] | Prediction:  [[ 120.72280884]\n",
      " [ 205.17903137]\n",
      " [ 234.89286804]]\n",
      "740 Cost:  202.897 | W:  [[ 2.78596497]\n",
      " [ 4.02108288]\n",
      " [ 1.98158944]\n",
      " [ 1.01541102]\n",
      " [-2.91779375]] | Prediction:  [[ 120.139328  ]\n",
      " [ 205.10466003]\n",
      " [ 235.65971375]]\n",
      "760 Cost:  188.575 | W:  [[ 2.81774592]\n",
      " [ 4.04913044]\n",
      " [ 1.99150002]\n",
      " [ 1.0123682 ]\n",
      " [-2.94863033]] | Prediction:  [[ 119.57892609]\n",
      " [ 205.0329895 ]\n",
      " [ 236.39648438]]\n",
      "780 Cost:  175.358 | W:  [[ 2.84819794]\n",
      " [ 4.07612896]\n",
      " [ 2.00104952]\n",
      " [ 1.00945556]\n",
      " [-2.97827697]] | Prediction:  [[ 119.04084778]\n",
      " [ 204.963974  ]\n",
      " [ 237.10427856]]\n",
      "800 Cost:  163.159 | W:  [[ 2.87737441]\n",
      " [ 4.10211992]\n",
      " [ 2.010252  ]\n",
      " [ 1.00666797]\n",
      " [-3.0067811 ]] | Prediction:  [[ 118.52410126]\n",
      " [ 204.89743042]\n",
      " [ 237.78430176]]\n",
      "820 Cost:  151.902 | W:  [[ 2.90532494]\n",
      " [ 4.12714148]\n",
      " [ 2.01912212]\n",
      " [ 1.0040009 ]\n",
      " [-3.03418684]] | Prediction:  [[ 118.02792358]\n",
      " [ 204.83332825]\n",
      " [ 238.43757629]]\n",
      "840 Cost:  141.512 | W:  [[ 2.93209767]\n",
      " [ 4.15123463]\n",
      " [ 2.02767158]\n",
      " [ 1.00144899]\n",
      " [-3.06053853]] | Prediction:  [[ 117.5514679 ]\n",
      " [ 204.77156067]\n",
      " [ 239.06523132]]\n",
      "860 Cost:  131.922 | W:  [[ 2.95774055]\n",
      " [ 4.17443466]\n",
      " [ 2.03591347]\n",
      " [ 0.99900758]\n",
      " [-3.08587718]] | Prediction:  [[ 117.09394073]\n",
      " [ 204.71194458]\n",
      " [ 239.66822815]]\n",
      "880 Cost:  123.07 | W:  [[ 2.98229814]\n",
      " [ 4.19677544]\n",
      " [ 2.0438602 ]\n",
      " [ 0.99667293]\n",
      " [-3.11024261]] | Prediction:  [[ 116.65458679]\n",
      " [ 204.65455627]\n",
      " [ 240.24757385]]\n",
      "900 Cost:  114.901 | W:  [[ 3.00581217]\n",
      " [ 4.21829224]\n",
      " [ 2.05152321]\n",
      " [ 0.99444032]\n",
      " [-3.13367367]] | Prediction:  [[ 116.23273468]\n",
      " [ 204.59916687]\n",
      " [ 240.80413818]]\n",
      "920 Cost:  107.36 | W:  [[ 3.02832389]\n",
      " [ 4.23901796]\n",
      " [ 2.05891347]\n",
      " [ 0.99230605]\n",
      " [-3.15620661]] | Prediction:  [[ 115.82769012]\n",
      " [ 204.54580688]\n",
      " [ 241.33888245]]\n",
      "940 Cost:  100.4 | W:  [[ 3.04987407]\n",
      " [ 4.25898266]\n",
      " [ 2.06604195]\n",
      " [ 0.99026591]\n",
      " [-3.17787743]] | Prediction:  [[ 115.43878174]\n",
      " [ 204.49429321]\n",
      " [ 241.85263062]]\n",
      "960 Cost:  93.9742 | W:  [[ 3.07049894]\n",
      " [ 4.27821636]\n",
      " [ 2.07291842]\n",
      " [ 0.98831648]\n",
      " [-3.19871926]] | Prediction:  [[ 115.06530762]\n",
      " [ 204.4446106 ]\n",
      " [ 242.34625244]]\n",
      "980 Cost:  88.0435 | W:  [[ 3.09023619]\n",
      " [ 4.29674768]\n",
      " [ 2.0795536 ]\n",
      " [ 0.98645437]\n",
      " [-3.2187655 ]] | Prediction:  [[ 114.70677185]\n",
      " [ 204.39671326]\n",
      " [ 242.82048035]]\n",
      "1000 Cost:  82.5676 | W:  [[ 3.10912132]\n",
      " [ 4.31460619]\n",
      " [ 2.08595634]\n",
      " [ 0.98467588]\n",
      " [-3.23804736]] | Prediction:  [[ 114.3625412 ]\n",
      " [ 204.35046387]\n",
      " [ 243.27619934]]\n",
      "1020 Cost:  77.5136 | W:  [[ 3.12718678]\n",
      " [ 4.33181524]\n",
      " [ 2.09213614]\n",
      " [ 0.98297733]\n",
      " [-3.25659442]] | Prediction:  [[ 114.03204346]\n",
      " [ 204.30587769]\n",
      " [ 243.71394348]]\n",
      "1040 Cost:  72.8468 | W:  [[ 3.14446521]\n",
      " [ 4.3484025 ]\n",
      " [ 2.09810138]\n",
      " [ 0.98135602]\n",
      " [-3.27443576]] | Prediction:  [[ 113.71468353]\n",
      " [ 204.26283264]\n",
      " [ 244.13459778]]\n",
      "1060 Cost:  68.5387 | W:  [[ 3.16098905]\n",
      " [ 4.36439276]\n",
      " [ 2.10386086]\n",
      " [ 0.97980857]\n",
      " [-3.29159999]] | Prediction:  [[ 113.41004181]\n",
      " [ 204.22131348]\n",
      " [ 244.53874207]]\n",
      "1080 Cost:  64.5604 | W:  [[ 3.17678666]\n",
      " [ 4.3798089 ]\n",
      " [ 2.10942149]\n",
      " [ 0.97833192]\n",
      " [-3.30811286]] | Prediction:  [[ 113.11753845]\n",
      " [ 204.18110657]\n",
      " [ 244.92704773]]\n",
      "1100 Cost:  60.8875 | W:  [[ 3.19188714]\n",
      " [ 4.39467287]\n",
      " [ 2.11479306]\n",
      " [ 0.976924  ]\n",
      " [-3.32400036]] | Prediction:  [[ 112.83674622]\n",
      " [ 204.14247131]\n",
      " [ 245.30020142]]\n",
      "1120 Cost:  57.4956 | W:  [[ 3.20631838]\n",
      " [ 4.40900564]\n",
      " [ 2.119982  ]\n",
      " [ 0.97558147]\n",
      " [-3.33928704]] | Prediction:  [[ 112.56711578]\n",
      " [ 204.10494995]\n",
      " [ 245.65864563]]\n",
      "1140 Cost:  54.3633 | W:  [[ 3.22010684]\n",
      " [ 4.42282963]\n",
      " [ 2.12499571]\n",
      " [ 0.97430217]\n",
      " [-3.35399723]] | Prediction:  [[ 112.30831146]\n",
      " [ 204.06880188]\n",
      " [ 246.00312805]]\n",
      "1160 Cost:  51.4708 | W:  [[ 3.23327804]\n",
      " [ 4.43616295]\n",
      " [ 2.12984157]\n",
      " [ 0.97308326]\n",
      " [-3.36815262]] | Prediction:  [[ 112.05993652]\n",
      " [ 204.03387451]\n",
      " [ 246.33410645]]\n",
      "1180 Cost:  48.7988 | W:  [[ 3.24585533]\n",
      " [ 4.44902754]\n",
      " [ 2.13452506]\n",
      " [ 0.97192246]\n",
      " [-3.38177538]] | Prediction:  [[ 111.8214798 ]\n",
      " [ 204.00006104]\n",
      " [ 246.65216064]]\n",
      "1200 Cost:  46.3313 | W:  [[ 3.25786352]\n",
      " [ 4.46144056]\n",
      " [ 2.13905311]\n",
      " [ 0.97081739]\n",
      " [-3.39488673]] | Prediction:  [[ 111.59256744]\n",
      " [ 203.96746826]\n",
      " [ 246.95774841]]\n",
      "1220 Cost:  44.0516 | W:  [[ 3.26932478]\n",
      " [ 4.47341967]\n",
      " [ 2.14343143]\n",
      " [ 0.96976608]\n",
      " [-3.40750718]] | Prediction:  [[ 111.37280273]\n",
      " [ 203.93588257]\n",
      " [ 247.25138855]]\n",
      "1240 Cost:  41.9455 | W:  [[ 3.28026009]\n",
      " [ 4.48498249]\n",
      " [ 2.14766622]\n",
      " [ 0.96876615]\n",
      " [-3.41965532]] | Prediction:  [[ 111.16188049]\n",
      " [ 203.90544128]\n",
      " [ 247.53361511]]\n",
      "1260 Cost:  39.9999 | W:  [[ 3.29069114]\n",
      " [ 4.49614382]\n",
      " [ 2.1517632 ]\n",
      " [ 0.9678157 ]\n",
      " [-3.43134928]] | Prediction:  [[ 110.95944214]\n",
      " [ 203.87594604]\n",
      " [ 247.80476379]]\n",
      "1280 Cost:  38.2022 | W:  [[ 3.30063653]\n",
      " [ 4.50692034]\n",
      " [ 2.15572739]\n",
      " [ 0.96691275]\n",
      " [-3.44260788]] | Prediction:  [[ 110.76516724]\n",
      " [ 203.84741211]\n",
      " [ 248.06529236]]\n",
      "1300 Cost:  36.5405 | W:  [[ 3.31011724]\n",
      " [ 4.51732922]\n",
      " [ 2.15956402]\n",
      " [ 0.96605533]\n",
      " [-3.45344853]] | Prediction:  [[ 110.57865143]\n",
      " [ 203.8197937 ]\n",
      " [ 248.3157196 ]]\n",
      "1320 Cost:  35.0049 | W:  [[ 3.31915092]\n",
      " [ 4.52738285]\n",
      " [ 2.16327834]\n",
      " [ 0.96524155]\n",
      " [-3.46388674]] | Prediction:  [[ 110.39971924]\n",
      " [ 203.79302979]\n",
      " [ 248.55632019]]\n",
      "1340 Cost:  33.5856 | W:  [[ 3.32775497]\n",
      " [ 4.53709459]\n",
      " [ 2.16687536]\n",
      " [ 0.96446979]\n",
      " [-3.47393894]] | Prediction:  [[ 110.22792816]\n",
      " [ 203.7671814 ]\n",
      " [ 248.78753662]]\n",
      "1360 Cost:  32.2732 | W:  [[ 3.33594656]\n",
      " [ 4.54647827]\n",
      " [ 2.17035961]\n",
      " [ 0.96373868]\n",
      " [-3.48361993]] | Prediction:  [[ 110.06312561]\n",
      " [ 203.74208069]\n",
      " [ 249.00975037]]\n",
      "1380 Cost:  31.0598 | W:  [[ 3.34374213]\n",
      " [ 4.55554819]\n",
      " [ 2.1737349 ]\n",
      " [ 0.96304613]\n",
      " [-3.49294519]] | Prediction:  [[ 109.90487671]\n",
      " [ 203.71780396]\n",
      " [ 249.22329712]]\n",
      "1400 Cost:  29.9377 | W:  [[ 3.35115814]\n",
      " [ 4.56431532]\n",
      " [ 2.17700601]\n",
      " [ 0.96239084]\n",
      " [-3.50192785]] | Prediction:  [[ 109.75312042]\n",
      " [ 203.69432068]\n",
      " [ 249.42855835]]\n",
      "1420 Cost:  28.8997 | W:  [[ 3.35820794]\n",
      " [ 4.57279253]\n",
      " [ 2.1801765 ]\n",
      " [ 0.96177125]\n",
      " [-3.51058149]] | Prediction:  [[ 109.60746765]\n",
      " [ 203.67152405]\n",
      " [ 249.62579346]]\n",
      "1440 Cost:  27.9395 | W:  [[ 3.36490726]\n",
      " [ 4.58098984]\n",
      " [ 2.18325043]\n",
      " [ 0.96118641]\n",
      " [-3.51891923]] | Prediction:  [[ 109.46770477]\n",
      " [ 203.6493988 ]\n",
      " [ 249.81533813]]\n",
      "1460 Cost:  27.0509 | W:  [[ 3.37126923]\n",
      " [ 4.58891869]\n",
      " [ 2.18623328]\n",
      " [ 0.96063405]\n",
      " [-3.52695322]] | Prediction:  [[ 109.33360291]\n",
      " [ 203.62800598]\n",
      " [ 249.99755859]]\n",
      "1480 Cost:  26.2285 | W:  [[ 3.37730765]\n",
      " [ 4.59658957]\n",
      " [ 2.18912673]\n",
      " [ 0.96011329]\n",
      " [-3.53469563]] | Prediction:  [[ 109.20500183]\n",
      " [ 203.60722351]\n",
      " [ 250.1726532 ]]\n",
      "1500 Cost:  25.4673 | W:  [[ 3.38303542]\n",
      " [ 4.60401344]\n",
      " [ 2.19193482]\n",
      " [ 0.95962322]\n",
      " [-3.5421586 ]] | Prediction:  [[ 109.0815506 ]\n",
      " [ 203.58706665]\n",
      " [ 250.34094238]]\n",
      "1520 Cost:  24.7621 | W:  [[ 3.3884654 ]\n",
      " [ 4.61119938]\n",
      " [ 2.19466114]\n",
      " [ 0.95916218]\n",
      " [-3.54935241]] | Prediction:  [[ 108.96315765]\n",
      " [ 203.56750488]\n",
      " [ 250.50276184]]\n",
      "1540 Cost:  24.1093 | W:  [[ 3.39360881]\n",
      " [ 4.61815691]\n",
      " [ 2.19730806]\n",
      " [ 0.95872897]\n",
      " [-3.55628753]] | Prediction:  [[ 108.8495636 ]\n",
      " [ 203.54856873]\n",
      " [ 250.6582489 ]]\n",
      "1560 Cost:  23.5041 | W:  [[ 3.3984766 ]\n",
      " [ 4.62489462]\n",
      " [ 2.19987965]\n",
      " [ 0.95832276]\n",
      " [-3.56297421]] | Prediction:  [[ 108.74065399]\n",
      " [ 203.53005981]\n",
      " [ 250.80769348]]\n",
      "1580 Cost:  22.9431 | W:  [[ 3.40308022]\n",
      " [ 4.63142109]\n",
      " [ 2.20237803]\n",
      " [ 0.95794272]\n",
      " [-3.56942248]] | Prediction:  [[ 108.63611603]\n",
      " [ 203.51211548]\n",
      " [ 250.9513855 ]]\n",
      "1600 Cost:  22.4232 | W:  [[ 3.40743041]\n",
      " [ 4.6377449 ]\n",
      " [ 2.20480657]\n",
      " [ 0.95758742]\n",
      " [-3.57564187]] | Prediction:  [[ 108.53590393]\n",
      " [ 203.49467468]\n",
      " [ 251.08946228]]\n",
      "1620 Cost:  21.9412 | W:  [[ 3.41153622]\n",
      " [ 4.64387226]\n",
      " [ 2.20716858]\n",
      " [ 0.95725602]\n",
      " [-3.58164048]] | Prediction:  [[ 108.43978119]\n",
      " [ 203.47782898]\n",
      " [ 251.22221375]]\n",
      "1640 Cost:  21.4936 | W:  [[ 3.41540837]\n",
      " [ 4.64981508]\n",
      " [ 2.20946527]\n",
      " [ 0.95694727]\n",
      " [-3.58742809]] | Prediction:  [[ 108.3476181 ]\n",
      " [ 203.46134949]\n",
      " [ 251.34985352]]\n",
      "1660 Cost:  21.0783 | W:  [[ 3.4190557 ]\n",
      " [ 4.65557718]\n",
      " [ 2.21169996]\n",
      " [ 0.95666051]\n",
      " [-3.59301233]] | Prediction:  [[ 108.2592392 ]\n",
      " [ 203.44535828]\n",
      " [ 251.47254944]]\n",
      "1680 Cost:  20.6927 | W:  [[ 3.42248726]\n",
      " [ 4.66116714]\n",
      " [ 2.21387458]\n",
      " [ 0.95639443]\n",
      " [-3.59840107]] | Prediction:  [[ 108.1745224 ]\n",
      " [ 203.42982483]\n",
      " [ 251.59048462]]\n",
      "1700 Cost:  20.3341 | W:  [[ 3.42571139]\n",
      " [ 4.66659069]\n",
      " [ 2.21599197]\n",
      " [ 0.95614904]\n",
      " [-3.60360289]] | Prediction:  [[ 108.09318542]\n",
      " [ 203.41459656]\n",
      " [ 251.70391846]]\n",
      "1720 Cost:  20.0011 | W:  [[ 3.42873669]\n",
      " [ 4.6718545 ]\n",
      " [ 2.21805453]\n",
      " [ 0.95592326]\n",
      " [-3.6086247 ]] | Prediction:  [[ 108.01529694]\n",
      " [ 203.39988708]\n",
      " [ 251.8129425 ]]\n",
      "1740 Cost:  19.6911 | W:  [[ 3.43157029]\n",
      " [ 4.67696476]\n",
      " [ 2.22006416]\n",
      " [ 0.95571643]\n",
      " [-3.61347294]] | Prediction:  [[ 107.94064331]\n",
      " [ 203.38546753]\n",
      " [ 251.91775513]]\n",
      "1760 Cost:  19.4029 | W:  [[ 3.43422127]\n",
      " [ 4.68192863]\n",
      " [ 2.22202277]\n",
      " [ 0.95552713]\n",
      " [-3.61815548]] | Prediction:  [[ 107.86907196]\n",
      " [ 203.37150574]\n",
      " [ 252.01855469]]\n",
      "1780 Cost:  19.1342 | W:  [[ 3.43669581]\n",
      " [ 4.68675041]\n",
      " [ 2.2239325 ]\n",
      " [ 0.95535499]\n",
      " [-3.62267756]] | Prediction:  [[ 107.8004837 ]\n",
      " [ 203.3578186 ]\n",
      " [ 252.11549377]]\n",
      "1800 Cost:  18.8841 | W:  [[ 3.43900132]\n",
      " [ 4.69143629]\n",
      " [ 2.22579479]\n",
      " [ 0.9551993 ]\n",
      " [-3.62704659]] | Prediction:  [[ 107.73467255]\n",
      " [ 203.34449768]\n",
      " [ 252.20864868]]\n",
      "1820 Cost:  18.6506 | W:  [[ 3.4411447 ]\n",
      " [ 4.69599152]\n",
      " [ 2.22761226]\n",
      " [ 0.95505959]\n",
      " [-3.63126826]] | Prediction:  [[ 107.67173004]\n",
      " [ 203.33154297]\n",
      " [ 252.29832458]]\n",
      "1840 Cost:  18.4332 | W:  [[ 3.44313192]\n",
      " [ 4.70042086]\n",
      " [ 2.22938609]\n",
      " [ 0.95493531]\n",
      " [-3.63534832]] | Prediction:  [[ 107.61131287]\n",
      " [ 203.31892395]\n",
      " [ 252.38450623]]\n",
      "1860 Cost:  18.2298 | W:  [[ 3.44496918]\n",
      " [ 4.70472956]\n",
      " [ 2.23111844]\n",
      " [ 0.95482528]\n",
      " [-3.639292  ]] | Prediction:  [[ 107.55349731]\n",
      " [ 203.30654907]\n",
      " [ 252.46739197]]\n",
      "1880 Cost:  18.0399 | W:  [[ 3.4466629 ]\n",
      " [ 4.70892286]\n",
      " [ 2.2328105 ]\n",
      " [ 0.95472944]\n",
      " [-3.64310527]] | Prediction:  [[ 107.49808502]\n",
      " [ 203.29452515]\n",
      " [ 252.5471344 ]]\n",
      "1900 Cost:  17.8622 | W:  [[ 3.44821882]\n",
      " [ 4.71300411]\n",
      " [ 2.23446393]\n",
      " [ 0.95464694]\n",
      " [-3.64679265]] | Prediction:  [[ 107.44502258]\n",
      " [ 203.2827301 ]\n",
      " [ 252.6237793 ]]\n",
      "1920 Cost:  17.6956 | W:  [[ 3.44964194]\n",
      " [ 4.7169776 ]\n",
      " [ 2.23608017]\n",
      " [ 0.95457745]\n",
      " [-3.65035915]] | Prediction:  [[ 107.39421082]\n",
      " [ 203.27119446]\n",
      " [ 252.69755554]]\n",
      "1940 Cost:  17.5394 | W:  [[ 3.45093799]\n",
      " [ 4.72084856]\n",
      " [ 2.23766041]\n",
      " [ 0.95452046]\n",
      " [-3.65380979]] | Prediction:  [[ 107.34548187]\n",
      " [ 203.25984192]\n",
      " [ 252.76846313]]\n",
      "1960 Cost:  17.3931 | W:  [[ 3.4521122 ]\n",
      " [ 4.72462034]\n",
      " [ 2.23920679]\n",
      " [ 0.95447546]\n",
      " [-3.65714931]] | Prediction:  [[ 107.29894257]\n",
      " [ 203.24890137]\n",
      " [ 252.83674622]]\n",
      "1980 Cost:  17.2557 | W:  [[ 3.45316911]\n",
      " [ 4.72829676]\n",
      " [ 2.24072027]\n",
      " [ 0.95444179]\n",
      " [-3.66038132]] | Prediction:  [[ 107.25426483]\n",
      " [ 203.23809814]\n",
      " [ 252.90240479]]\n",
      "2000 Cost:  17.1265 | W:  [[ 3.45411348]\n",
      " [ 4.7318821 ]\n",
      " [ 2.24220181]\n",
      " [ 0.95441914]\n",
      " [-3.66351056]] | Prediction:  [[ 107.21160126]\n",
      " [ 203.22756958]\n",
      " [ 252.96554565]]\n",
      "2020 Cost:  17.0048 | W:  [[ 3.45494962]\n",
      " [ 4.73537922]\n",
      " [ 2.24365258]\n",
      " [ 0.95440674]\n",
      " [-3.66654086]] | Prediction:  [[ 107.17073822]\n",
      " [ 203.21722412]\n",
      " [ 253.02630615]]\n",
      "2040 Cost:  16.8902 | W:  [[ 3.45568252]\n",
      " [ 4.73879242]\n",
      " [ 2.24507427]\n",
      " [ 0.95440459]\n",
      " [-3.66947603]] | Prediction:  [[ 107.13167572]\n",
      " [ 203.20710754]\n",
      " [ 253.08474731]]\n",
      "2060 Cost:  16.7824 | W:  [[ 3.45631433]\n",
      " [ 4.74212408]\n",
      " [ 2.24646807]\n",
      " [ 0.9544124 ]\n",
      " [-3.67232084]] | Prediction:  [[ 107.09422302]\n",
      " [ 203.19728088]\n",
      " [ 253.14100647]]\n",
      "2080 Cost:  16.6799 | W:  [[ 3.45685124]\n",
      " [ 4.74537802]\n",
      " [ 2.24783492]\n",
      " [ 0.95442951]\n",
      " [-3.67507744]] | Prediction:  [[ 107.05845642]\n",
      " [ 203.18751526]\n",
      " [ 253.19517517]]\n",
      "2100 Cost:  16.5832 | W:  [[ 3.4572978 ]\n",
      " [ 4.74855661]\n",
      " [ 2.24917579]\n",
      " [ 0.95445544]\n",
      " [-3.67775011]] | Prediction:  [[ 107.02417755]\n",
      " [ 203.17791748]\n",
      " [ 253.24725342]]\n",
      "2120 Cost:  16.4918 | W:  [[ 3.45765567]\n",
      " [ 4.75166321]\n",
      " [ 2.25049114]\n",
      " [ 0.95448989]\n",
      " [-3.68034196]] | Prediction:  [[ 106.99151611]\n",
      " [ 203.16867065]\n",
      " [ 253.29737854]]\n",
      "2140 Cost:  16.4049 | W:  [[ 3.45792937]\n",
      " [ 4.75470066]\n",
      " [ 2.25178266]\n",
      " [ 0.9545325 ]\n",
      " [-3.68285584]] | Prediction:  [[ 106.96013641]\n",
      " [ 203.15943909]\n",
      " [ 253.34565735]]\n",
      "2160 Cost:  16.3226 | W:  [[ 3.45812154]\n",
      " [ 4.75767136]\n",
      " [ 2.2530508 ]\n",
      " [ 0.95458305]\n",
      " [-3.6852951 ]] | Prediction:  [[ 106.93027496]\n",
      " [ 203.15049744]\n",
      " [ 253.3921051 ]]\n",
      "2180 Cost:  16.2441 | W:  [[ 3.45823598]\n",
      " [ 4.76057863]\n",
      " [ 2.25429654]\n",
      " [ 0.95464081]\n",
      " [-3.6876626 ]] | Prediction:  [[ 106.90170288]\n",
      " [ 203.1416626 ]\n",
      " [ 253.43682861]]\n",
      "2200 Cost:  16.1695 | W:  [[ 3.45827603]\n",
      " [ 4.76342344]\n",
      " [ 2.25552154]\n",
      " [ 0.95470619]\n",
      " [-3.68996096]] | Prediction:  [[ 106.87438202]\n",
      " [ 203.13301086]\n",
      " [ 253.47987366]]\n",
      "2220 Cost:  16.0979 | W:  [[ 3.45824409]\n",
      " [ 4.7662096 ]\n",
      " [ 2.25672579]\n",
      " [ 0.95477837]\n",
      " [-3.69219351]] | Prediction:  [[ 106.84830475]\n",
      " [ 203.12443542]\n",
      " [ 253.52140808]]\n",
      "2240 Cost:  16.0297 | W:  [[ 3.45814371]\n",
      " [ 4.76893854]\n",
      " [ 2.25790977]\n",
      " [ 0.95485753]\n",
      " [-3.69436193]] | Prediction:  [[ 106.82338715]\n",
      " [ 203.11602783]\n",
      " [ 253.56132507]]\n",
      "2260 Cost:  15.9643 | W:  [[ 3.45797706]\n",
      " [ 4.77161312]\n",
      " [ 2.25907493]\n",
      " [ 0.95494276]\n",
      " [-3.69646907]] | Prediction:  [[ 106.79959869]\n",
      " [ 203.10771179]\n",
      " [ 253.59976196]]\n",
      "2280 Cost:  15.9018 | W:  [[ 3.45774722]\n",
      " [ 4.77423429]\n",
      " [ 2.26022148]\n",
      " [ 0.95503438]\n",
      " [-3.69851732]] | Prediction:  [[ 106.77696991]\n",
      " [ 203.09963989]\n",
      " [ 253.63677979]]\n",
      "2300 Cost:  15.842 | W:  [[ 3.45745635]\n",
      " [ 4.77680492]\n",
      " [ 2.26135015]\n",
      " [ 0.95513177]\n",
      " [-3.70050883]] | Prediction:  [[ 106.75528717]\n",
      " [ 203.09165955]\n",
      " [ 253.67242432]]\n",
      "2320 Cost:  15.7846 | W:  [[ 3.45710778]\n",
      " [ 4.77932739]\n",
      " [ 2.2624619 ]\n",
      " [ 0.95523483]\n",
      " [-3.70244646]] | Prediction:  [[ 106.73461151]\n",
      " [ 203.0838623 ]\n",
      " [ 253.70678711]]\n",
      "2340 Cost:  15.7288 | W:  [[ 3.45670319]\n",
      " [ 4.78180265]\n",
      " [ 2.26355743]\n",
      " [ 0.95534325]\n",
      " [-3.70433116]] | Prediction:  [[ 106.71497345]\n",
      " [ 203.07608032]\n",
      " [ 253.73988342]]\n",
      "2360 Cost:  15.675 | W:  [[ 3.45624471]\n",
      " [ 4.78423357]\n",
      " [ 2.26463723]\n",
      " [ 0.95545691]\n",
      " [-3.70616651]] | Prediction:  [[ 106.69618988]\n",
      " [ 203.06837463]\n",
      " [ 253.77175903]]\n",
      "2380 Cost:  15.6232 | W:  [[ 3.45573497]\n",
      " [ 4.78662062]\n",
      " [ 2.26570177]\n",
      " [ 0.95557559]\n",
      " [-3.70795345]] | Prediction:  [[ 106.67834473]\n",
      " [ 203.06082153]\n",
      " [ 253.80247498]]\n",
      "2400 Cost:  15.5732 | W:  [[ 3.45517588]\n",
      " [ 4.78896618]\n",
      " [ 2.26675224]\n",
      " [ 0.95569909]\n",
      " [-3.70969439]] | Prediction:  [[ 106.66133118]\n",
      " [ 203.05345154]\n",
      " [ 253.83209229]]\n",
      "2420 Cost:  15.5249 | W:  [[ 3.45456982]\n",
      " [ 4.79127169]\n",
      " [ 2.26778841]\n",
      " [ 0.95582718]\n",
      " [-3.7113905 ]] | Prediction:  [[ 106.64510345]\n",
      " [ 203.04612732]\n",
      " [ 253.86058044]]\n",
      "2440 Cost:  15.4777 | W:  [[ 3.45391774]\n",
      " [ 4.79353857]\n",
      " [ 2.26881075]\n",
      " [ 0.95595962]\n",
      " [-3.71304345]] | Prediction:  [[ 106.62973022]\n",
      " [ 203.03890991]\n",
      " [ 253.88813782]]\n",
      "2460 Cost:  15.4321 | W:  [[ 3.45322251]\n",
      " [ 4.79576778]\n",
      " [ 2.26982069]\n",
      " [ 0.95609641]\n",
      " [-3.7146554 ]] | Prediction:  [[ 106.6150589 ]\n",
      " [ 203.03181458]\n",
      " [ 253.91465759]]\n",
      "2480 Cost:  15.3875 | W:  [[ 3.45248532]\n",
      " [ 4.79796171]\n",
      " [ 2.270818  ]\n",
      " [ 0.95623708]\n",
      " [-3.71622825]] | Prediction:  [[ 106.60108948]\n",
      " [ 203.02467346]\n",
      " [ 253.94017029]]\n",
      "2500 Cost:  15.3444 | W:  [[ 3.45170832]\n",
      " [ 4.80012178]\n",
      " [ 2.27180338]\n",
      " [ 0.95638168]\n",
      " [-3.71776247]] | Prediction:  [[ 106.587883  ]\n",
      " [ 203.01785278]\n",
      " [ 253.96488953]]\n",
      "2520 Cost:  15.3021 | W:  [[ 3.45089269]\n",
      " [ 4.80224848]\n",
      " [ 2.27277684]\n",
      " [ 0.95652974]\n",
      " [-3.71926045]] | Prediction:  [[ 106.57531738]\n",
      " [ 203.01095581]\n",
      " [ 253.98864746]]\n",
      "2540 Cost:  15.2611 | W:  [[ 3.45004058]\n",
      " [ 4.80434322]\n",
      " [ 2.27373958]\n",
      " [ 0.95668143]\n",
      " [-3.72072339]] | Prediction:  [[ 106.56336212]\n",
      " [ 203.00419617]\n",
      " [ 254.0115509 ]]\n",
      "2560 Cost:  15.2205 | W:  [[ 3.44915271]\n",
      " [ 4.80640793]\n",
      " [ 2.27469158]\n",
      " [ 0.95683646]\n",
      " [-3.72215247]] | Prediction:  [[ 106.55204773]\n",
      " [ 202.99742126]\n",
      " [ 254.03370667]]\n",
      "2580 Cost:  15.1811 | W:  [[ 3.44823122]\n",
      " [ 4.80844307]\n",
      " [ 2.27563286]\n",
      " [ 0.95699453]\n",
      " [-3.72354913]] | Prediction:  [[ 106.54134369]\n",
      " [ 202.99082947]\n",
      " [ 254.05505371]]\n",
      "2600 Cost:  15.1425 | W:  [[ 3.44727707]\n",
      " [ 4.81045055]\n",
      " [ 2.27656388]\n",
      " [ 0.95715618]\n",
      " [-3.72491455]] | Prediction:  [[ 106.53118134]\n",
      " [ 202.98425293]\n",
      " [ 254.07563782]]\n",
      "2620 Cost:  15.1043 | W:  [[ 3.44629216]\n",
      " [ 4.81243038]\n",
      " [ 2.27748561]\n",
      " [ 0.95732057]\n",
      " [-3.72624993]] | Prediction:  [[ 106.52160645]\n",
      " [ 202.97775269]\n",
      " [ 254.0955658 ]]\n",
      "2640 Cost:  15.0672 | W:  [[ 3.44527721]\n",
      " [ 4.81438446]\n",
      " [ 2.27839804]\n",
      " [ 0.95748788]\n",
      " [-3.72755647]] | Prediction:  [[ 106.51248932]\n",
      " [ 202.97134399]\n",
      " [ 254.11477661]]\n",
      "2660 Cost:  15.0304 | W:  [[ 3.44423389]\n",
      " [ 4.81631184]\n",
      " [ 2.27930164]\n",
      " [ 0.95765799]\n",
      " [-3.72883511]] | Prediction:  [[ 106.5039444 ]\n",
      " [ 202.96492004]\n",
      " [ 254.133255  ]]\n",
      "2680 Cost:  14.9944 | W:  [[ 3.44316316]\n",
      " [ 4.81821632]\n",
      " [ 2.28019643]\n",
      " [ 0.95783043]\n",
      " [-3.73008704]] | Prediction:  [[ 106.49588776]\n",
      " [ 202.95872498]\n",
      " [ 254.1512146 ]]\n",
      "2700 Cost:  14.9587 | W:  [[ 3.44206667]\n",
      " [ 4.82009697]\n",
      " [ 2.28108287]\n",
      " [ 0.95800567]\n",
      " [-3.73131394]] | Prediction:  [[ 106.48820496]\n",
      " [ 202.9523468 ]\n",
      " [ 254.16847229]]\n",
      "2720 Cost:  14.9239 | W:  [[ 3.44094467]\n",
      " [ 4.8219552 ]\n",
      " [ 2.28196216]\n",
      " [ 0.95818335]\n",
      " [-3.73251605]] | Prediction:  [[ 106.48103333]\n",
      " [ 202.94624329]\n",
      " [ 254.18519592]]\n",
      "2740 Cost:  14.8894 | W:  [[ 3.43979859]\n",
      " [ 4.82379198]\n",
      " [ 2.28283286]\n",
      " [ 0.95836312]\n",
      " [-3.73369408]] | Prediction:  [[ 106.47428894]\n",
      " [ 202.94013977]\n",
      " [ 254.20132446]]\n",
      "2760 Cost:  14.8553 | W:  [[ 3.43862963]\n",
      " [ 4.8256073 ]\n",
      " [ 2.28369665]\n",
      " [ 0.95854497]\n",
      " [-3.73484969]] | Prediction:  [[ 106.46794128]\n",
      " [ 202.93403625]\n",
      " [ 254.21690369]]\n",
      "2780 Cost:  14.8216 | W:  [[ 3.43743825]\n",
      " [ 4.82740259]\n",
      " [ 2.28455305]\n",
      " [ 0.95872897]\n",
      " [-3.73598313]] | Prediction:  [[ 106.46196747]\n",
      " [ 202.92799377]\n",
      " [ 254.23196411]]\n",
      "2800 Cost:  14.7884 | W:  [[ 3.43622613]\n",
      " [ 4.82917833]\n",
      " [ 2.28540277]\n",
      " [ 0.95891511]\n",
      " [-3.73709559]] | Prediction:  [[ 106.45638275]\n",
      " [ 202.92201233]\n",
      " [ 254.246521  ]]\n",
      "2820 Cost:  14.7554 | W:  [[ 3.43499374]\n",
      " [ 4.83093596]\n",
      " [ 2.28624558]\n",
      " [ 0.95910335]\n",
      " [-3.73818803]] | Prediction:  [[ 106.45122528]\n",
      " [ 202.91612244]\n",
      " [ 254.26062012]]\n",
      "2840 Cost:  14.7228 | W:  [[ 3.43374205]\n",
      " [ 4.83267546]\n",
      " [ 2.28708243]\n",
      " [ 0.95929343]\n",
      " [-3.73926067]] | Prediction:  [[ 106.44637299]\n",
      " [ 202.91026306]\n",
      " [ 254.27427673]]\n",
      "2860 Cost:  14.6907 | W:  [[ 3.43247151]\n",
      " [ 4.83439732]\n",
      " [ 2.28791332]\n",
      " [ 0.95948493]\n",
      " [-3.74031472]] | Prediction:  [[ 106.44181824]\n",
      " [ 202.9044342 ]\n",
      " [ 254.28744507]]\n",
      "2880 Cost:  14.6587 | W:  [[ 3.43118334]\n",
      " [ 4.83610296]\n",
      " [ 2.2887373 ]\n",
      " [ 0.95967811]\n",
      " [-3.74135089]] | Prediction:  [[ 106.43760681]\n",
      " [ 202.89863586]\n",
      " [ 254.30020142]]\n",
      "2900 Cost:  14.627 | W:  [[ 3.42987823]\n",
      " [ 4.83779287]\n",
      " [ 2.28955579]\n",
      " [ 0.9598729 ]\n",
      " [-3.74236941]] | Prediction:  [[ 106.4337616 ]\n",
      " [ 202.89292908]\n",
      " [ 254.31256104]]\n",
      "2920 Cost:  14.5954 | W:  [[ 3.4285574 ]\n",
      " [ 4.83946657]\n",
      " [ 2.2903688 ]\n",
      " [ 0.9600693 ]\n",
      " [-3.74337125]] | Prediction:  [[ 106.43013   ]\n",
      " [ 202.88713074]\n",
      " [ 254.32450867]]\n",
      "2940 Cost:  14.5645 | W:  [[ 3.42722058]\n",
      " [ 4.84112549]\n",
      " [ 2.29117656]\n",
      " [ 0.96026695]\n",
      " [-3.74435711]] | Prediction:  [[ 106.42683411]\n",
      " [ 202.88154602]\n",
      " [ 254.33609009]]\n",
      "2960 Cost:  14.5333 | W:  [[ 3.42586899]\n",
      " [ 4.84277058]\n",
      " [ 2.29197907]\n",
      " [ 0.96046627]\n",
      " [-3.74532747]] | Prediction:  [[ 106.42383575]\n",
      " [ 202.87590027]\n",
      " [ 254.34733582]]\n",
      "2980 Cost:  14.5025 | W:  [[ 3.42450333]\n",
      " [ 4.84440136]\n",
      " [ 2.29277706]\n",
      " [ 0.96066689]\n",
      " [-3.74628353]] | Prediction:  [[ 106.42105865]\n",
      " [ 202.87026978]\n",
      " [ 254.35821533]]\n",
      "3000 Cost:  14.4722 | W:  [[ 3.42312407]\n",
      " [ 4.84601879]\n",
      " [ 2.2935698 ]\n",
      " [ 0.96086848]\n",
      " [-3.74722481]] | Prediction:  [[ 106.41854858]\n",
      " [ 202.86477661]\n",
      " [ 254.36871338]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFz9JREFUeJzt3X+QXeV93/H3d3e1YoWM0C8LIWEERukESIODTNXYk3pC\nHRS7DbRjO+pMbP1BzUyhHXumnQ40M23yB1O7MzU105oZEjwWJDVmbCcwSUiLZSeeTMqPBWN+YwQI\nI1lCCwKJH0LS7n77x32uuNqro7OSdnXvct6vmTv33Of8uM/DQfroPM9z7onMRJKkTgO9roAkqf8Y\nDpKkLoaDJKmL4SBJ6mI4SJK6GA6SpC6GgySpi+EgSepiOEiSugz1ugInatmyZblmzZpeV0OS5pSH\nH3741cxcXrfdnA2HNWvWMDo62utqSNKcEhEvTWc7u5UkSV0MB0lSF8NBktTFcJAkdTEcJEldDAdJ\nUhfDQZLUpXHh8NC2PXzt/z7LwfHJXldFkvpW48LhkZde5+YfbmV80nCQpCqNCwdJUr1ph0NEDEbE\nTyLiL8rnJRFxX0Q8V94Xd2x7Q0RsjYhnI+KKjvJLI+Lxsu7miIhSPj8ivlPKH4iINTPXREnS8Tqe\nK4cvAU93fL4e2JKZa4Et5TMRcSGwEbgI2AB8IyIGyz63AF8E1pbXhlJ+NfB6Zl4A3AR89YRacxwy\nZ/sbJGnumlY4RMRq4NPAH3cUXwlsLsubgas6yu/MzAOZ+SKwFbgsIlYCZ2Tm/ZmZwO1T9mkf67vA\n5e2ripk2O0eVpPeX6V45/A/gPwKdo7grMnNnWd4FrCjLq4CXO7bbXspWleWp5Ufsk5njwF5g6TTr\nJkmaYbXhEBH/DNidmQ9XbVOuBGa9oyYiromI0YgYHRsbO6lj2askSdWmc+XwMeB3ImIbcCfwmxHx\nJ8ArpauI8r67bL8DOKdj/9WlbEdZnlp+xD4RMQQsAl6bWpHMvDUz12XmuuXLa59VcVSB/UqSVKc2\nHDLzhsxcnZlraA00/zAzfw+4B9hUNtsE3F2W7wE2lhlI59EaeH6wdEHti4j1ZTzhC1P2aR/rM+U7\n/Me9JPXIyTwJ7ivAXRFxNfAS8DmAzHwyIu4CngLGgesyc6Lscy3wLWAEuLe8AG4D7oiIrcAeWiEk\nSeqR4wqHzPwb4G/K8mvA5RXb3QjceJTyUeDio5S/C3z2eOpysrwwkaRqjbtD2qmsklSvceEgSapn\nOEiSujQ2HBxxkKRqjQ0HSVI1w0GS1MVwkCR1aWw4eJuDJFVrXDjM0i+BS9L7SuPCQZJUr7nhYLeS\nJFVqXDjYqSRJ9RoXDpKkeoaDJKlLY8MhHXSQpEqNCwdnskpSvcaFgySpnuEgSerS2HDw5zMkqVrj\nwsEhB0mq17hwkCTVMxwkSV0aGw4OOUhStcaFgz/ZLUn1GhcOkqR6jQ2HdC6rJFVqXDjYqyRJ9RoX\nDpKkeoaDJKlLY8PBEQdJqta4cHDIQZLqNS4cJEn1DAdJUpfGhoO3OUhSteaFgzc6SFKt5oWDJKlW\nY8MhncwqSZUaFw52KklSvcaFgySpXm04RMRpEfFgRPw0Ip6MiD8s5Usi4r6IeK68L+7Y54aI2BoR\nz0bEFR3ll0bE42XdzVEerhAR8yPiO6X8gYhYM/NNlSRN13SuHA4Av5mZvwpcAmyIiPXA9cCWzFwL\nbCmfiYgLgY3ARcAG4BsRMViOdQvwRWBteW0o5VcDr2fmBcBNwFdnoG3H5pCDJFWqDYdseat8nFde\nCVwJbC7lm4GryvKVwJ2ZeSAzXwS2ApdFxErgjMy8P1sPU7h9yj7tY30XuDxm6ZFtzmSVpHrTGnOI\niMGIeBTYDdyXmQ8AKzJzZ9lkF7CiLK8CXu7YfXspW1WWp5YfsU9mjgN7gaXH3RpJ0oyYVjhk5kRm\nXgKspnUVcPGU9ckp6KiJiGsiYjQiRsfGxmb76ySpsY5rtlJmvgH8iNZYwSulq4jyvrtstgM4p2O3\n1aVsR1meWn7EPhExBCwCXjvK99+amesyc93y5cuPp+rdbTmpvSXp/W06s5WWR8SZZXkE+CTwDHAP\nsKlstgm4uyzfA2wsM5DOozXw/GDpgtoXEevLeMIXpuzTPtZngB/mLD3kObzTQZJqDU1jm5XA5jLj\naAC4KzP/IiL+H3BXRFwNvAR8DiAzn4yIu4CngHHgusycKMe6FvgWMALcW14AtwF3RMRWYA+t2U6S\npB6pDYfMfAz4yFHKXwMur9jnRuDGo5SPAhcfpfxd4LPTqK8k6RRo7B3S/mS3JFVrXDh4n4Mk1Wtc\nOEiS6jU2HPzJbkmq1rhwsFdJkuo1LhwkSfUMB0lSl8aGg1NZJala48LBqaySVK9x4SBJqmc4SJK6\nNDYcHHKQpGqNCwd/sluS6jUuHCRJ9QwHSVKXxobDLD1oTpLeF5oXDg45SFKt5oWDJKlWY8PBXiVJ\nqta4cLBXSZLqNS4cJEn1DAdJUhfDQZLUpXHhEP5mtyTValw4SJLqGQ6SpC6NDQfvc5Ckao0LB0cc\nJKle48JBklSvseGQPgtOkio1LhycySpJ9RoXDpKkeoaDJKlLY8PBqaySVK1x4eCYgyTVa1w4SJLq\nGQ6SpC6NDQeHHCSpWuPCIfwBDUmqVRsOEXFORPwoIp6KiCcj4kulfElE3BcRz5X3xR373BARWyPi\n2Yi4oqP80oh4vKy7OcrDFSJifkR8p5Q/EBFrZr6pR0qnK0lSpelcOYwD/z4zLwTWA9dFxIXA9cCW\nzFwLbCmfKes2AhcBG4BvRMRgOdYtwBeBteW1oZRfDbyemRcANwFfnYG2HVV7tpLRIEnVasMhM3dm\n5iNl+U3gaWAVcCWwuWy2GbiqLF8J3JmZBzLzRWArcFlErATOyMz7s/XP9tun7NM+1neBy8NHtklS\nzxzXmEPp7vkI8ACwIjN3llW7gBVleRXwcsdu20vZqrI8tfyIfTJzHNgLLD2euh0ve5Ukqdq0wyEi\nFgLfA76cmfs615UrgVn/6zYiromI0YgYHRsbO9FjzHCtJOn9Z1rhEBHzaAXDn2bm90vxK6WriPK+\nu5TvAM7p2H11KdtRlqeWH7FPRAwBi4DXptYjM2/NzHWZuW758uXTqfoxeOkgSVWmM1spgNuApzPz\nax2r7gE2leVNwN0d5RvLDKTzaA08P1i6oPZFxPpyzC9M2ad9rM8AP8xZmk7kdYMk1RuaxjYfAz4P\nPB4Rj5ay/wR8BbgrIq4GXgI+B5CZT0bEXcBTtGY6XZeZE2W/a4FvASPAveUFrfC5IyK2AntozXaa\nVY45SFK12nDIzL+j+h/cl1fscyNw41HKR4GLj1L+LvDZurrMBKeySlI975CWJHVpXDi02a0kSdUa\nFw7OZJWkeo0Lh7Z01EGSKjUuHNoXDnYrSVK1xoWDJKle48Lh8FRWrxwkqVLjwsF7pCWpXgPDocUB\naUmq1rhwcCqrJNVrXDi0OeYgSdUaFw5eOEhSveaFg/1KklSrceHQZreSJFVrXDh43SBJ9RoXDm1O\nZZWkao0LB4ccJKle48KhzTEHSarWuHDwMaGSVK954eCQtCTValw4tKX9SpJUqXnh4IWDJNVqXjgU\nXjdIUrXGhYMXDpJUr3Hh0OaQgyRVa1w4vPfDe6aDJFVpXjj0ugKSNAc0Lhza7FaSpGqNCwd/W0mS\n6jUuHNq8cJCkao0Lh/bPZ9itJEnVmhcOditJUq3GhUObv60kSdUaFw5eOEhSvcaFQzsdJr1wkKRK\njQuHwwPSzleSpEqNC4cBfz1Dkmo1LxxKOtitJEnVGhcO7QuHSWcrSVKl2nCIiG9GxO6IeKKjbElE\n3BcRz5X3xR3rboiIrRHxbERc0VF+aUQ8XtbdHOXnUSNifkR8p5Q/EBFrZraJXe0B7FWSpGOZzpXD\nt4ANU8quB7Zk5lpgS/lMRFwIbAQuKvt8IyIGyz63AF8E1pZX+5hXA69n5gXATcBXT7Qx0zFweLaS\n8SBJVWrDITN/DOyZUnwlsLksbwau6ii/MzMPZOaLwFbgsohYCZyRmfdn6+6z26fs0z7Wd4HLI2bv\nPubDVw6GgyRVOtExhxWZubMs7wJWlOVVwMsd220vZavK8tTyI/bJzHFgL7D0BOtVq33lYDZIUrWT\nHpAuVwKn5K/aiLgmIkYjYnRsbOyEjjEQzlaSpDonGg6vlK4iyvvuUr4DOKdju9WlbEdZnlp+xD4R\nMQQsAl472pdm5q2ZuS4z1y1fvvwEq97imIMkVTvRcLgH2FSWNwF3d5RvLDOQzqM18Pxg6YLaFxHr\ny3jCF6bs0z7WZ4Af5iwOCAyEP9ktSXWG6jaIiG8DnwCWRcR24L8AXwHuioirgZeAzwFk5pMRcRfw\nFDAOXJeZE+VQ19Ka+TQC3FteALcBd0TEVloD3xtnpGUVBkocOiAtSdVqwyEz/1XFqssrtr8RuPEo\n5aPAxUcpfxf4bF09Zkr7t5Ucc5Ckao27Q/rwbCVvg5OkSo0Lh3C2kiTValw4vHefg+kgSVUaFw7v\nXTkYDpJUpXHh4B3SklSvgeHgmIMk1WlcOLTZrSRJ1RoXDgPvzWWVJFVoXjj4PAdJqtW4cPAOaUmq\n17hw8A5pSarXuHDwDmlJqtfAcGi9e4e0JFVrXDj4PAdJqtfAcGi9O1tJkqo1LhycrSRJ9ZoXDj4J\nTpJqNS4cBsuYw7iXDpJUqXHhMH+o1eSD45M9rokk9a/GhcPQ4ACDA2E4SNIxNC4cAIYHBzgwPtHr\nakhS32pkOMyfN8ABrxwkqVIzw2FowG4lSTqGRobD8NAA7x6yW0mSqjQyHM4cGWbPO4d6XQ1J6luN\nDIcPLVnAU7/Yy563D/a6KpLUlxoZDr+3/lz27j/Eb930Y/78Jzu8W1qSpmhkOPzjDy/lz6/7GKsW\nj/Dl7zzK7956P8/s2tfraklS32hkOABcdPYi/uzf/Dr/9V/+Cj975U0+ffPfcf33HuMXb+zvddUk\nqedirnaprFu3LkdHR2fkWK+/fZCvb3mO//3AzyHg8+vP5dpPfJilC+fPyPElqV9ExMOZua52O8Ph\nPdtff4ev/+A5vvfIduYNDvDZdav51x8/nzXLTp/R75GkXjEcTsLzY2/xRz9+ge8/soNDk5NsuOgs\nPr/+XNafv5SB9tOCJGkOMhxmwO4332Xz32/jT+7/OXv3H+LcpQv43Y+ew2cuXc0HP3DarH63JM0G\nw2EGvXtogr9+YhfffvDnPPDiHgYHgl//8FI+/SsrueKis1h8+vApqYcknSzDYZa8MPYW33tkO3/5\n2E62vfbO4aD4p7+8gn/yS8sdn5DU1wyHWZaZPLVzH3/52E7ufWIXL776NgBrli7gE//gg3zsgmV8\ndM1izlzgVYWk/mE4nGLbXn2bv/3ZGH/7szH+/vlXefdQ61dff2nFQtatWcJH1yzmknMWc+6SBQ5q\nS+oZw6GH3j00wWPb9/LQtj08tG0PD297nTcPjAOwcP4QF648gwvPPoOLVy3il1d+gPOXLWRkeLDH\ntZbUBIZDH5mYTJ7d9SaP73iDJ3+xjyd27OXpnW+yv/xseAScvWiE85efzoeXL+T85adz3rLTWXXm\nCGefOcJp8wwOSTNjuuEwdCoqMx0RsQH4OjAI/HFmfqXHVZoxgwPBhWe3rhbaJiaTF199m2d27eOF\nsbd5fuwtXhh7m7tGX+adg0c+a2LZwvmsOvM0Vi0e4exFI5y16DSWLZzfen1gmGUL57NkwbDdVZJm\nTF+EQ0QMAv8L+CSwHXgoIu7JzKd6W7PZMzgQXPDBhVzwwYVHlGcmr+w7wIuvvs0v3tjPjjf2H35/\nZtebbHl691EfcToQsOT0+SxbOMziBcOcMTLEopF5nHHaPBaNzGPRgveWzxgZ4vT5QyyYN8SC+YMs\nGB7ktKFBw0XSYX0RDsBlwNbMfAEgIu4ErgTet+FQJSI4a9FpnLXo6DfZZSb79o8z9tYBXm2/3jzA\nq28dPPx57/5DvPjq2+zbP87e/YcOd1/VGZnXCoqR4db7guEhFgwPMn9ogOGhAYaHBpk3GK3Pg+2y\nAYYHB5k3FAwPDnRsO8DgwABDA8FABEMDweBgMFiWBwZK2ZRXq2yAwWht395/IFr/bQYCgoCgqyyi\n1UU3EEHQsS4MPel49Us4rAJe7vi8HfhHPapLX4sIFi1oXQlMveqocnB8kn3vHmLf/kPsLa93Dk7w\nzsEJ9h8cP7z8Tlne3/58qLX+rQPjHByf5OD4JAfGJzk4MXn486GJScYn+3/cKlp50gqOEhhHfC7L\nxJFl7+3/3qeYctwp33TUdVX7RMX23fscPeCOONZJHveURugp/LJT2a5T9Q+RL12+ln/+q2fP6nf0\nSzhMS0RcA1wD8KEPfajHtZk7hocGDo9RzIaJyeTQRAmOjvCYmJxkYhLGJyeZmMyu1/hkMpHJxER5\nL2WTU94nJidJYHIyW+/J4Qc0TWaSWcpoLWdm2aasB2iX8d66LOvax21v3z5uW+ecjXK0rvLWOirW\nVRyr4rjd66axT+X2U447je+YbadyEswp/WfLKfyyRSPzZv07+iUcdgDndHxeXcqOkJm3ArdCa7bS\nqama6rS6hAadVSW9j/TLw34eAtZGxHkRMQxsBO7pcZ0kqbH64sohM8cj4t8C/4fWVNZvZuaTPa6W\nJDVWX4QDQGb+FfBXva6HJKl/upUkSX3EcJAkdTEcJEldDAdJUhfDQZLUZc7+ZHdEjAEvneDuy4BX\nZ7A6vWRb+s/7pR1gW/rVybTl3MxcXrfRnA2HkxERo9P5PfO5wLb0n/dLO8C29KtT0Ra7lSRJXQwH\nSVKXpobDrb2uwAyyLf3n/dIOsC39atbb0sgxB0nSsTX1ykGSdAyNC4eI2BARz0bE1oi4vtf1qRMR\n2yLi8Yh4NCJGS9mSiLgvIp4r74s7tr+htO3ZiLiidzWHiPhmROyOiCc6yo677hFxaflvsDUibo4e\nPPezoi1/EBE7yrl5NCI+1e9tiYhzIuJHEfFURDwZEV8q5XPuvByjLXPxvJwWEQ9GxE9LW/6wlPfu\nvGRmY160fg78eeB8YBj4KXBhr+tVU+dtwLIpZf8NuL4sXw98tSxfWNo0HzivtHWwh3X/DeDXgCdO\npu7Ag8B6Wk98vBf47T5pyx8A/+Eo2/ZtW4CVwK+V5Q8APyv1nXPn5RhtmYvnJYCFZXke8ECpT8/O\nS9OuHC4DtmbmC5l5ELgTuLLHdToRVwKby/Jm4KqO8jsz80BmvghspdXmnsjMHwN7phQfV90jYiVw\nRmben63/82/v2OeUqWhLlb5tS2buzMxHyvKbwNO0nuE+587LMdpSpZ/bkpn5Vvk4r7ySHp6XpoXD\nKuDljs/bOfb/TP0ggR9ExMPReoY2wIrM3FmWdwEryvJcaN/x1n1VWZ5a3i/+XUQ8Vrqd2pf8c6It\nEbEG+Aitf6XO6fMypS0wB89LRAxGxKPAbuC+zOzpeWlaOMxFH8/MS4DfBq6LiN/oXFn+dTAnp5zN\n5boXt9DqorwE2An8995WZ/oiYiHwPeDLmbmvc91cOy9HacucPC+ZOVH+rK+mdRVw8ZT1p/S8NC0c\ndgDndHxeXcr6VmbuKO+7gT+j1U30Srl8pLzvLpvPhfYdb913lOWp5T2Xma+UP9CTwB/xXhdeX7cl\nIubR+sv0TzPz+6V4Tp6Xo7Vlrp6Xtsx8A/gRsIEenpemhcNDwNqIOC8ihoGNwD09rlOliDg9Ij7Q\nXgZ+C3iCVp03lc02AXeX5XuAjRExPyLOA9bSGpzqJ8dV93JJvS8i1pdZF1/o2Ken2n9oi39B69xA\nH7elfO9twNOZ+bWOVXPuvFS1ZY6el+URcWZZHgE+CTxDL8/LqRyR74cX8ClasxqeB36/1/Wpqev5\ntGYk/BR4sl1fYCmwBXgO+AGwpGOf3y9te5YezOqZUv9v07qsP0Sr7/PqE6k7sI7WH/Dngf9JuXmz\nD9pyB/A48Fj5w7qy39sCfJxW18RjwKPl9am5eF6O0Za5eF7+IfCTUucngP9cynt2XrxDWpLUpWnd\nSpKkaTAcJEldDAdJUhfDQZLUxXCQJHUxHCRJXQwHSVIXw0GS1OX/Az/XN/dI5HrtAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa7324e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build Graph\n",
    "## x, y data 정의\n",
    "x_data = [ [23.,   35.,  48.,  62.,  83.]\n",
    "          ,[38.,   46.,  59.,  74.,  95.]\n",
    "          ,[35.,   42.,  46.,  53.,  60.]]\n",
    "y_data = [[110.], [198.], [257.]]\n",
    "\n",
    "## X, Y 정의\n",
    "X = tf.placeholder(tf.float32, shape = [None, 5])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "## W, b 정의\n",
    "W = tf.Variable(tf.random_normal([5,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "## model 정의 >> matrix 곱으로 표현\n",
    "# model = x1 * w1 + x2 * w2 + x3 * w3 + b \n",
    "model = tf.matmul(X, W) + b\n",
    "\n",
    "## loss function 정의(cost 최소화)\n",
    "cost = tf.reduce_mean(tf.square(model - Y))\n",
    "\n",
    "## Gradient Descent (Gradient optimization)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5).minimize(cost)\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# Run Graph\n",
    "## Session option (Launch Graph in a session)\n",
    "sess = tf.Session()\n",
    "\n",
    "## 변수 초기화 (반드시 실행 필요!!)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# Update Graph\n",
    "cost_list = []\n",
    "\n",
    "## Fit the line\n",
    "for step in range(3001):\n",
    "    cost_val, W_val, model_val, _ = sess.run([cost, W, model, optimizer]\n",
    "                                      , feed_dict = {X:x_data, Y:y_data})\n",
    "    cost_list.append(cost_val)\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"| W: \", W_val, \"| Prediction: \", model_val)\n",
    "        \n",
    "plt.plot(cost_list)        \n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------\n",
    "## 4-3) Softmax Classification\n",
    "\n",
    "실습데이터; https://archive.ics.uci.edu/ml/machine-learning-databases/zoo/zoo.data\n",
    "\n",
    "### (1) Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...,  0.  0.  1.]\n",
      " [ 1.  0.  0. ...,  1.  0.  1.]\n",
      " [ 0.  0.  1. ...,  1.  0.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0. ...,  1.  0.  1.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " [ 0.  1.  1. ...,  1.  0.  0.]] [[ 0.]\n",
      " [ 0.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 5.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 1.]\n",
      " [ 5.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 6.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 6.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 1.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 5.]\n",
      " [ 0.]\n",
      " [ 6.]\n",
      " [ 1.]]\n",
      "(101, 16) (101, 1)\n"
     ]
    }
   ],
   "source": [
    "## Seeding\n",
    "tf.set_random_seed(6100)\n",
    "\n",
    "## data loading\n",
    "data = np.loadtxt('D:/2_Edu/5_Deep_Learning_Tensor/Practice/zoo.txt', delimiter = ',', dtype = np.float32)\n",
    "\n",
    "## data split\n",
    "x_data = data[:, 0:-1]\n",
    "y_data = data[:, [-1]]\n",
    "\n",
    "print(x_data, y_data)\n",
    "print(x_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_5:0\", shape=(?, 1), dtype=int32)\n",
      "Tensor(\"one_hot_2:0\", shape=(?, 1, 7), dtype=float32)\n",
      "Tensor(\"Reshape_11:0\", shape=(?, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Classification Number 정의 >> 1 ~ 7\n",
    "class_num = 7 \n",
    "\n",
    "## X, Y 정의\n",
    "X = tf.placeholder(shape = [None, 16], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 1],  dtype = tf.int32); print(Y)\n",
    "\n",
    "##-- Y >> one hot encoding (0, 1)\n",
    "Y_one_hot = tf.one_hot(Y, class_num)                   ; print(Y_one_hot)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, class_num])     ; print(Y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## W, b 정의\n",
    "W = tf.Variable(tf.random_normal([16, class_num]))\n",
    "b = tf.Variable(tf.random_normal([class_num]))\n",
    "\n",
    "## model 정의\n",
    "model      = tf.matmul(X, W) + b\n",
    "hypothesis = tf.nn.softmax(model)\n",
    "\n",
    "## loss function 정의(cost 최소화) >> softmax\n",
    "##-- **_with_logits: Classification 처리 없는 상태에서 계산 (softmax 전단계)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = model, labels = Y_one_hot))\n",
    "\n",
    "## Gradient Descent (Gradient optimization)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5).minimize(cost)\n",
    "\n",
    "## Classification Accuracy\n",
    "prediction         = tf.argmax(hypothesis, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2~3) Run & Update Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     0\tLoss: 4.712\tAcc: 43.56%\n",
      "Step:   100\tLoss: 4.709\tAcc: 43.56%\n",
      "Step:   200\tLoss: 4.707\tAcc: 43.56%\n",
      "Step:   300\tLoss: 4.704\tAcc: 43.56%\n",
      "Step:   400\tLoss: 4.701\tAcc: 43.56%\n",
      "Step:   500\tLoss: 4.698\tAcc: 43.56%\n",
      "Step:   600\tLoss: 4.695\tAcc: 43.56%\n",
      "Step:   700\tLoss: 4.693\tAcc: 43.56%\n",
      "Step:   800\tLoss: 4.690\tAcc: 43.56%\n",
      "Step:   900\tLoss: 4.687\tAcc: 43.56%\n",
      "Step:  1000\tLoss: 4.684\tAcc: 43.56%\n",
      "Step:  1100\tLoss: 4.682\tAcc: 43.56%\n",
      "Step:  1200\tLoss: 4.679\tAcc: 43.56%\n",
      "Step:  1300\tLoss: 4.676\tAcc: 43.56%\n",
      "Step:  1400\tLoss: 4.673\tAcc: 43.56%\n",
      "Step:  1500\tLoss: 4.670\tAcc: 43.56%\n",
      "Step:  1600\tLoss: 4.668\tAcc: 43.56%\n",
      "Step:  1700\tLoss: 4.665\tAcc: 43.56%\n",
      "Step:  1800\tLoss: 4.662\tAcc: 43.56%\n",
      "Step:  1900\tLoss: 4.659\tAcc: 43.56%\n",
      "Step:  2000\tLoss: 4.657\tAcc: 43.56%\n",
      "Step:  2100\tLoss: 4.654\tAcc: 43.56%\n",
      "Step:  2200\tLoss: 4.651\tAcc: 43.56%\n",
      "Step:  2300\tLoss: 4.648\tAcc: 43.56%\n",
      "Step:  2400\tLoss: 4.646\tAcc: 43.56%\n",
      "Step:  2500\tLoss: 4.643\tAcc: 43.56%\n",
      "Step:  2600\tLoss: 4.640\tAcc: 43.56%\n",
      "Step:  2700\tLoss: 4.638\tAcc: 43.56%\n",
      "Step:  2800\tLoss: 4.635\tAcc: 43.56%\n",
      "Step:  2900\tLoss: 4.632\tAcc: 43.56%\n",
      "Step:  3000\tLoss: 4.629\tAcc: 43.56%\n",
      "Step:  3100\tLoss: 4.627\tAcc: 43.56%\n",
      "Step:  3200\tLoss: 4.624\tAcc: 43.56%\n",
      "Step:  3300\tLoss: 4.621\tAcc: 43.56%\n",
      "Step:  3400\tLoss: 4.619\tAcc: 43.56%\n",
      "Step:  3500\tLoss: 4.616\tAcc: 43.56%\n",
      "Step:  3600\tLoss: 4.613\tAcc: 43.56%\n",
      "Step:  3700\tLoss: 4.610\tAcc: 43.56%\n",
      "Step:  3800\tLoss: 4.608\tAcc: 43.56%\n",
      "Step:  3900\tLoss: 4.605\tAcc: 43.56%\n",
      "Step:  4000\tLoss: 4.602\tAcc: 43.56%\n",
      "Step:  4100\tLoss: 4.600\tAcc: 43.56%\n",
      "Step:  4200\tLoss: 4.597\tAcc: 43.56%\n",
      "Step:  4300\tLoss: 4.594\tAcc: 43.56%\n",
      "Step:  4400\tLoss: 4.592\tAcc: 43.56%\n",
      "Step:  4500\tLoss: 4.589\tAcc: 43.56%\n",
      "Step:  4600\tLoss: 4.586\tAcc: 43.56%\n",
      "Step:  4700\tLoss: 4.584\tAcc: 43.56%\n",
      "Step:  4800\tLoss: 4.581\tAcc: 43.56%\n",
      "Step:  4900\tLoss: 4.578\tAcc: 43.56%\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 3.0 | Prediction: 0 | True Y: 3 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 3.0 | Prediction: 4 | True Y: 3 | [False]\n",
      "Pred: 3.0 | Prediction: 0 | True Y: 3 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 1.0 | Prediction: 0 | True Y: 1 | [False]\n",
      "Pred: 3.0 | Prediction: 0 | True Y: 3 | [False]\n",
      "Pred: 6.0 | Prediction: 0 | True Y: 6 | [False]\n",
      "Pred: 6.0 | Prediction: 0 | True Y: 6 | [False]\n",
      "Pred: 6.0 | Prediction: 4 | True Y: 6 | [False]\n",
      "Pred: 1.0 | Prediction: 0 | True Y: 1 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 3.0 | Prediction: 0 | True Y: 3 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 1.0 | Prediction: 0 | True Y: 1 | [False]\n",
      "Pred: 1.0 | Prediction: 2 | True Y: 1 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 1.0 | Prediction: 0 | True Y: 1 | [False]\n",
      "Pred: 5.0 | Prediction: 4 | True Y: 5 | [False]\n",
      "Pred: 4.0 | Prediction: 0 | True Y: 4 | [False]\n",
      "Pred: 4.0 | Prediction: 0 | True Y: 4 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 5.0 | Prediction: 0 | True Y: 5 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 1.0 | Prediction: 0 | True Y: 1 | [False]\n",
      "Pred: 3.0 | Prediction: 2 | True Y: 3 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 1.0 | Prediction: 0 | True Y: 1 | [False]\n",
      "Pred: 3.0 | Prediction: 0 | True Y: 3 | [False]\n",
      "Pred: 5.0 | Prediction: 0 | True Y: 5 | [False]\n",
      "Pred: 5.0 | Prediction: 0 | True Y: 5 | [False]\n",
      "Pred: 1.0 | Prediction: 0 | True Y: 1 | [False]\n",
      "Pred: 5.0 | Prediction: 0 | True Y: 5 | [False]\n",
      "Pred: 1.0 | Prediction: 2 | True Y: 1 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 6.0 | Prediction: 4 | True Y: 6 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 5.0 | Prediction: 0 | True Y: 5 | [False]\n",
      "Pred: 4.0 | Prediction: 0 | True Y: 4 | [False]\n",
      "Pred: 6.0 | Prediction: 0 | True Y: 6 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 1.0 | Prediction: 0 | True Y: 1 | [False]\n",
      "Pred: 1.0 | Prediction: 0 | True Y: 1 | [False]\n",
      "Pred: 1.0 | Prediction: 0 | True Y: 1 | [False]\n",
      "Pred: 1.0 | Prediction: 2 | True Y: 1 | [False]\n",
      "Pred: 3.0 | Prediction: 0 | True Y: 3 | [False]\n",
      "Pred: 3.0 | Prediction: 0 | True Y: 3 | [False]\n",
      "Pred: 2.0 | Prediction: 2 | True Y: 2 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 1.0 | Prediction: 0 | True Y: 1 | [False]\n",
      "Pred: 6.0 | Prediction: 0 | True Y: 6 | [False]\n",
      "Pred: 3.0 | Prediction: 2 | True Y: 3 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 2.0 | Prediction: 6 | True Y: 2 | [False]\n",
      "Pred: 6.0 | Prediction: 0 | True Y: 6 | [False]\n",
      "Pred: 1.0 | Prediction: 0 | True Y: 1 | [False]\n",
      "Pred: 1.0 | Prediction: 0 | True Y: 1 | [False]\n",
      "Pred: 2.0 | Prediction: 2 | True Y: 2 | [True]\n",
      "Pred: 6.0 | Prediction: 2 | True Y: 6 | [False]\n",
      "Pred: 3.0 | Prediction: 2 | True Y: 3 | [False]\n",
      "Pred: 1.0 | Prediction: 2 | True Y: 1 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 6.0 | Prediction: 4 | True Y: 6 | [False]\n",
      "Pred: 3.0 | Prediction: 0 | True Y: 3 | [False]\n",
      "Pred: 1.0 | Prediction: 0 | True Y: 1 | [False]\n",
      "Pred: 5.0 | Prediction: 4 | True Y: 5 | [False]\n",
      "Pred: 4.0 | Prediction: 4 | True Y: 4 | [True]\n",
      "Pred: 2.0 | Prediction: 0 | True Y: 2 | [False]\n",
      "Pred: 2.0 | Prediction: 0 | True Y: 2 | [False]\n",
      "Pred: 3.0 | Prediction: 0 | True Y: 3 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 1.0 | Prediction: 0 | True Y: 1 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 5.0 | Prediction: 0 | True Y: 5 | [False]\n",
      "Pred: 0.0 | Prediction: 0 | True Y: 0 | [True]\n",
      "Pred: 6.0 | Prediction: 2 | True Y: 6 | [False]\n",
      "Pred: 1.0 | Prediction: 2 | True Y: 1 | [False]\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    ## training\n",
    "    for step in range(5000):\n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "        \n",
    "        ## training log\n",
    "        if step % 100 == 0:\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(step, loss, acc))\n",
    "                \n",
    "    # predict\n",
    "    pred = sess.run(prediction, feed_dict={X: x_data})\n",
    "    # y_data: (N,1) = flatten => (N, ) matches pred.shape\n",
    "    for pred_val, y_val in zip(pred, y_data.flatten()):\n",
    "        print(\"Pred: {} | Prediction: {} | True Y: {} | [{}]\".format(y_val, pred_val, int(y_val), pred_val == int(y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "--------------------------------------------------------------------------------\n",
    "\n",
    "*End of Code*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
